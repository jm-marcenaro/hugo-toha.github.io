[{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/basic/_index.bn/","summary":"","tags":null,"title":"Go বেসিক"},{"categories":null,"contents":" Hello World A sample go program is show here.\npackage main import \u0026#34;fmt\u0026#34; func main() { message := greetMe(\u0026#34;world\u0026#34;) fmt.Println(message) } func greetMe(name string) string { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34; } Run the program as below:\n$ go run hello.go Variables Normal Declaration:\nvar msg string msg = \u0026#34;Hello\u0026#34; Shortcut:\nmsg := \u0026#34;Hello\u0026#34; Constants const Phi = 1.618 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/basic/introduction/","summary":"\u003c!-- A Sample Program --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eHello World\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cp\u003eA sample go program is show here.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003epackage\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;fmt\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003emessage\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003egreetMe\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;world\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintln\u003c/span\u003e(\u003cspan style=\"color:#a6e22e\"\u003emessage\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003egreetMe\u003c/span\u003e(\u003cspan style=\"color:#a6e22e\"\u003ename\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003estring\u003c/span\u003e) \u003cspan style=\"color:#66d9ef\"\u003estring\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Hello, \u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ename\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;!\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eRun the program as below:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ go run hello.go\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Declaring Variables --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eVariables\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cp\u003e\u003cstrong\u003eNormal Declaration:\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003evar\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emsg\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003estring\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003emsg\u003c/span\u003e = \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Hello\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cp\u003e\u003cstrong\u003eShortcut:\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003emsg\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Hello\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Declaring Constants --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eConstants\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003econst\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ePhi\u003c/span\u003e = \u003cspan style=\"color:#ae81ff\"\u003e1.618\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e","tags":null,"title":"Introduction"},{"categories":null,"contents":" Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.Println(\u0026#34;Value is\u0026#34;, b) func getPointer () (myPointer *int) { a := 234 return \u0026amp;a a := new(int) *a = 234 Pointers point to a memory location of a variable. Go is fully garbage-collected.\nType Conversion i := 2 f := float64(i) u := uint(i) Slice slice := []int{2, 3, 4} slice := []byte(\u0026#34;Hello\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/basic/types/","summary":"\u003c!-- String Type --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eStrings\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003estr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Hello\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eMultiline string\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003estr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e`Multiline\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003estring`\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Number Types --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eNumbers\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cp\u003eTypical types\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003enum\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e          \u003cspan style=\"color:#75715e\"\u003e// int\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003enum\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e3.\u003c/span\u003e         \u003cspan style=\"color:#75715e\"\u003e// float64\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003enum\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e4i\u003c/span\u003e     \u003cspan style=\"color:#75715e\"\u003e// complex128\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003enum\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e byte(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;a\u0026#39;\u003c/span\u003e)  \u003cspan style=\"color:#75715e\"\u003e// byte (alias for uint8)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eOther Types\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003evar\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eu\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003euint\u003c/span\u003e = \u003cspan style=\"color:#ae81ff\"\u003e7\u003c/span\u003e        \u003cspan style=\"color:#75715e\"\u003e// uint (unsigned)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003evar\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ep\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003efloat32\u003c/span\u003e = \u003cspan style=\"color:#ae81ff\"\u003e22.7\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e// 32-bit float\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!----------- Arrays  ------\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eArrays\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e// var numbers [5]int\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003enumbers\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e [\u003cspan style=\"color:#f92672\"\u003e...\u003c/span\u003e]\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e{\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Pointers --\u003e\n\u003cdiv class=\"note-card medium-note\"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003ePointers\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e () {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003eb\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003egetPointer\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintln\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Value is\u0026#34;\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eb\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003egetPointer\u003c/span\u003e () (\u003cspan style=\"color:#a6e22e\"\u003emyPointer\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003ea\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e234\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003ea\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003ea\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e new(\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003ea\u003c/span\u003e = \u003cspan style=\"color:#ae81ff\"\u003e234\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003ePointers point to a memory location of a variable. Go is fully garbage-collected.\u003c/p\u003e","tags":null,"title":"Basic Types"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/advanced/_index.bn/","summary":"","tags":null,"title":"অ্যাডভান্সড"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) Switch switch day { case \u0026#34;sunday\u0026#34;: // cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default! fallthrough case \u0026#34;saturday\u0026#34;: rest() default: work() } Loop for count := 0; count \u0026lt;= 10; count++ { fmt.Println(\u0026#34;My counter is at\u0026#34;, count) } entry := []string{\u0026#34;Jack\u0026#34;,\u0026#34;John\u0026#34;,\u0026#34;Jones\u0026#34;} for i, val := range entry { fmt.Printf(\u0026#34;At position %d, the character %s is present\\n\u0026#34;, i, val) n := 0 x := 42 for n != x { n := guess() } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/basic/flow-control/","summary":"\u003c!-- Condition --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eCondition\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;sunday\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e||\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;saturday\u0026#34;\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003erest\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e} \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;monday\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eisTired\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003egroan\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e} \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003ework\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003e_\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003edoThing\u003c/span\u003e(); \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintln\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Uh oh\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Switch --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eSwitch\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eswitch\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#66d9ef\"\u003ecase\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;sunday\u0026#34;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e// cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default!\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e    \u003cspan style=\"color:#66d9ef\"\u003efallthrough\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#66d9ef\"\u003ecase\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;saturday\u0026#34;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003erest\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#66d9ef\"\u003edefault\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003ework\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Loop --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eLoop\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ecount\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e; \u003cspan style=\"color:#a6e22e\"\u003ecount\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e10\u003c/span\u003e; \u003cspan style=\"color:#a6e22e\"\u003ecount\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e++\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintln\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;My counter is at\u0026#34;\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003ecount\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003eentry\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e []\u003cspan style=\"color:#66d9ef\"\u003estring\u003c/span\u003e{\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Jack\u0026#34;\u003c/span\u003e,\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;John\u0026#34;\u003c/span\u003e,\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Jones\u0026#34;\u003c/span\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ei\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eval\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003erange\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eentry\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintf\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;At position %d, the character %s is present\\n\u0026#34;\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003ei\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eval\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003en\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003ex\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e42\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003en\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ex\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003en\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eguess\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e","tags":null,"title":"Flow Control"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/advanced/files/","summary":"\u003c!-- Condition --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eCondition\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;sunday\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e||\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;saturday\u0026#34;\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003erest\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e} \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;monday\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eisTired\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003egroan\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e} \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003ework\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003e_\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003edoThing\u003c/span\u003e(); \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintln\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Uh oh\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e","tags":null,"title":"File Manipulation"},{"categories":null,"contents":" Variable NAME=\u0026#34;John\u0026#34; echo $NAME echo \u0026#34;$NAME\u0026#34; echo \u0026#34;${NAME} Condition if [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; fi ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/bash/basic/","summary":"\u003c!-- Variable --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eVariable\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eNAME\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;John\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eecho $NAME\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eecho \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e$NAME\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eecho \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e${\u003c/span\u003eNAME\u003cspan style=\"color:#e6db74\"\u003e}\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Condition --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eCondition\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e[[\u003c/span\u003e -z \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e$string\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e]]\u003c/span\u003e; \u003cspan style=\"color:#66d9ef\"\u003ethen\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  echo \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;String is empty\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eelif\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e[[\u003c/span\u003e -n \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e$string\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e]]\u003c/span\u003e; \u003cspan style=\"color:#66d9ef\"\u003ethen\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  echo \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;String is not empty\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efi\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e","tags":null,"title":"Bash Variables"},{"categories":null,"contents":"Project Overview In this post, we\u0026rsquo;ll explore the capabilities of GDAL tools alongside Python to automate the process and calculate the mean slope of multiple basins from a Digital Elevation Model (DEM).\nTo begin with, we\u0026rsquo;ll need to set up an Anaconda environment with GDAL installed in it. I strongly recommend following the steps detailed in this tutorial.\nThe project is reproducible and available on my (Github repository)[https://github.com/jm-marcenaro/Personal-blog-posts], feel free to visit!\nHands on the code Once we\u0026rsquo;ve got our environment set up, lets move forward with the code. We\u0026rsquo;ll start by importing the necessary libraries and defining the path to de DEM and Shapefile containing the basins from where we want to extract the mean slope.\n# Libraries import os import subprocess import re # Path to DEM file DEM = r\u0026#34;DEMs/dem_01.tif\u0026#34; # Path to shapefile SHP = r\u0026#34;SHPs/basins_01.shp\u0026#34; Next up, we\u0026rsquo;ll define a list with the basins name or ID. This information can be exctracted from the dbf file.\n# List of basins ID Bs = [ \u0026#34;B-01\u0026#34;, \u0026#34;B-02\u0026#34;, \u0026#34;B-03\u0026#34;, \u0026#34;B-04\u0026#34;, \u0026#34;B-05\u0026#34;, \u0026#34;B-06\u0026#34;, \u0026#34;B-07\u0026#34;,\u0026#34;B-08\u0026#34;, \u0026#34;B-09\u0026#34;, \u0026#34;B-10\u0026#34;, \u0026#34;B-11\u0026#34;, \u0026#34;B-12\u0026#34;, \u0026#34;B-13\u0026#34;, \u0026#34;B-14\u0026#34;, \u0026#34;B-15\u0026#34;, \u0026#34;B-16\u0026#34;, \u0026#34;B-17\u0026#34;, \u0026#34;B-18\u0026#34;, \u0026#34;B-19\u0026#34; ] We are now ready to create our workflow, which will consist of the following steps:\nClip the DEM: For each basin polygon, we\u0026rsquo;ll clip the DEM and save it as a .tif file. Compute Slope: Using the clipped DEM, we\u0026rsquo;ll calculate the slope and write the output to a new .tif file. Calculate Statistics: From each slope file, we will compute statistical values and save them to a .txt file. Extract Mean Slope: Using Python regular expressions, we\u0026rsquo;ll read each of these .txt files and extract the mean slope value. Store and Summarize: We\u0026rsquo;ll store the mean slope value of each basin in a dictionary. Once the loop is completed, a final .txt file will summarize the mean slope for all basins. The code will look like this:\n# Empty dictionary to store outputs DICT_SLs = {} # Iterate over each basin for B in Bs: print(f\u0026#34;{B}:\u0026#34;) print(\u0026#34;- Clipping DEM.\u0026#34;) # Path to output file OUT_1 = os.path.join(\u0026#39;Output\u0026#39;, f\u0026#39;DEM_{B}.tif\u0026#39;) # Generate the command to clip CMD_2 = f\u0026#34;{CMD_1} \u0026amp;\u0026amp; gdalwarp -overwrite -of GTiff -cutline {SHP} -cwhere \\\u0026#34;ID_1=\u0026#39;{B}\u0026#39;\\\u0026#34; -dstnodata -9999 -crop_to_cutline {DEM} {OUT_1}\u0026#34; # Execute the command subprocess.run(CMD_2, stdout=subprocess.DEVNULL) # Calculate slopes from clipped DEM print(f\u0026#34;- Calculating slope.\u0026#34;) # Path to output file OUT_2 = os.path.join(\u0026#39;Output\u0026#39;, f\u0026#39;SL_{B}.tif\u0026#39;) # Generate the command to calculate slope CMD_3 = f\u0026#34;{CMD_1} \u0026amp;\u0026amp; gdaldem slope {OUT_1} {OUT_2} -of GTiff -b 1 -s 1.0 -p\u0026#34; # Execute the command subprocess.run(CMD_3, stdout=subprocess.DEVNULL) # Read slope file and compute statistics over it. print(f\u0026#34;- Analysing slope file.\u0026#34;) # Path to output file OUT_3 = os.path.join(\u0026#39;Output\u0026#39;, f\u0026#39;SL_{B}.txt\u0026#39;) # Generate the command to calculate statistics CMD_4 = f\u0026#34;{CMD_1} \u0026amp;\u0026amp; gdalinfo -stats {OUT_2} \u0026gt; {OUT_3}\u0026#34; # Execute the command subprocess.run(CMD_4, stdout=subprocess.DEVNULL) # Open txt file and extract mean slope with open(OUT_3, \u0026#39;r\u0026#39;) as file: TXT = file.read() # Regular expression to find the value of STATISTICS_MEAN SL_1 = re.findall(r\u0026#34;STATISTICS_MEAN=([\\d.]+)\u0026#34;, TXT) SL_2 = float(SL_1[0]) print(f\u0026#34;- Mean slope: {SL_2:.2f} %\\n\u0026#34;) # Store value in dictionary DICT_SLs[f\u0026#34;{B}\u0026#34;] = SL_2 # Write dicitionary to a txt file with open(os.path.join(\u0026#34;Output\u0026#34;, \u0026#34;SLs.txt\u0026#34;), \u0026#39;w\u0026#39;) as F: F.write(str(DICT_SLs)) print(\u0026#34;Created SLs.txt containing the mean slope of each basin.\u0026#34;) Let\u0026rsquo;s get into more detail with some aspects of the code:\nThe variable CMD_2 constructs the GDAL command to clip the DEM to each polygon from the shapefile. In each iteration of the for loop it is filtering by the ID_1 field from the shapefile. The variable CMD_3 constructs the GDAL command to calculate the slope from each clipped DEM. Options -b 1 -s 1.0 -p are declaring that we\u0026rsquo;ll use the first band from the tif file, that the aspect ratio is equal to 1 and that the output should be expressed as percentage rather than degrees. Conclusion In this post, we explored how to calculate the mean slope of multiple basins from a DEM using GDAL commands and Python to automate the process.\nThe possibilities for geospatial analysis are vast, and mastering these tools can significantly enhance your data analysis capabilities. In my case, I\u0026rsquo;ve utilized this workflow to facilitate the process of calculating the concentration time of multiple basins in my hydrological analysis.\nFeel free to adapt this code for your own projects. Thank you for reading, and I hope you found this tutorial helpful!\n","date":"September 27, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/gdal/gdal_1/","summary":"\u003ch2 id=\"project-overview\"\u003eProject Overview\u003c/h2\u003e\n\u003cp\u003eIn this post, we\u0026rsquo;ll explore the capabilities of GDAL tools alongside Python to automate the process and calculate the mean slope of multiple basins from a Digital Elevation Model (DEM).\u003c/p\u003e\n\u003cp\u003eTo begin with, we\u0026rsquo;ll need to set up an Anaconda environment with GDAL installed in it. I strongly recommend following the steps detailed in this \u003ca href=\"https://courses.spatialthoughts.com/gdal-tools.html#setting-up-the-environment\" target=\"_blank\" rel=\"noopener\"\u003etutorial.\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe project is reproducible and available on my (Github repository)[https://github.com/jm-marcenaro/Personal-blog-posts], feel free to visit!\u003c/p\u003e","tags":null,"title":"Calculate slopes from a DEM using GDAL and Python"},{"categories":null,"contents":"Project Overview In this opportunity we\u0026rsquo;ll go over a project developed through the combination of Google Earth Engine and Node.js once again. Data we\u0026rsquo;ll be retrieved and processed through GEE Python API and afterwards served to a local website interface using Node.js\nWe’ll walk through:\nRetrieving and processing data from Google Earth Engine using Python, serving this data through a local Node.js server and, building a responsive dashboard for data visualization. By the end of this project, you’ll learn how to integrate these powerful tools to visualize complex geospatial datasets in real time. The project is reproducible and available on my Github repository so you can follow along.\nHere’s a preview of the final website interface. It features a true-color GOES animation over Argentina for a date of interest.\nProject structure The project structure is shown below. The main directories are:\nGEE: Contains the Python script that retrieves and stores data from GEE. public: Contains the HTML structure, JavaScript for interactivity, and CSS for styling. /. ├── GEE │ ├── GIS │ │ ├── ROI.shp # Shapefile representing the ROI │ │ └── Grid.shp # Shapefile representing the grid │ ├── GOES.py # Python script that downloads images from GEE │ └── Output │ ├── PNGs # Folder containing the downloaded and processed images │ └── TSs.json # File with the timestamps of the images ├── public │ ├── index.html # HTML structure │ ├── ui.js # User interface in JavaScript │ ├── styles.css # Stylesheet ├── images │ ├── readme_01.png # Images for the README ├── server.js # Node.js server with Express.js ├── package.json # Node.js dependencies └── README.md # README file Retrieving data from GEE Python API The Python script GOES.py downloads true-color GOES-16 satellite images over Argentina for a specific date and time of interest, plus the 6 hours preceding it and sampled every 30 minutes. It processes these images by scaling the red, blue, and near-infrared bands, creating a synthetic green band, and saves them as PNGs. Additionally, it generates a timestamp file for tracking when each image was captured. For more details on processing true-color GOES-16 images, you can refer to this article.\nServing through a local Node.js server The server.js script sets up a Node.js server using Express.js to serve the web interface. It hosts the frontend from the public directory and serves processed images from the GEE/Output/PNGs folder as well.\nIt provides endpoints to list available images /images and timestamps /timestamps. Additionally, it allows end users to trigger the Python script /run-script that downloads and processes GOES-16 images based on a date of interest as explained before.\nBuilding a responsive dashboard for data visualization The website is built using a combination of HTML, JavaScript, and CSS. Let’s break it up and explore what each component does:\nHTML The index.html file creates the structure of the web interface. It allows users to input a date and fetch GOES-16 satellite images by triggering the GOES.py script. It includes a text input for the date, buttons to retrieve images, and navigation controls to browse through the downloaded images.\nJavascript The ui.js script controls the front-end behavior. It fetches satellite images and timestamps from the server, displays them, and allows navigation through the images using \u0026ldquo;Previous\u0026rdquo; and \u0026ldquo;Next\u0026rdquo; buttons. Users can input a specific date or select the current time by clicking on \u0026ldquo;Now!\u0026rdquo;. The Python script in triggered once the \u0026ldquo;Get images\u0026rdquo; button is clicked.\nBesides, it disables navigation during the GOES.py script execution and updates the displayed image, timestamp, and image counter accordingly.\nCSS The CSS styles the layout centering and formatting the image display, input, and buttons. It provides responsive designs for the image container, timestamp display, and navigation buttons. It attempt to ensure an organized, visually clean interface with hover effects and a loading overlay during script execution to enhence the user experience.\nConclusion The project integrates a Python backend and a user-friendly frontend to display GOES-16 satellite images over Argentina allowing users to track weather and environmental changes. Users can select specific dates, fetch images, and navigate through them with ease, offering a smooth experience.\n","date":"September 27, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/nodejs/nodejs_2/","summary":"\u003ch2 id=\"project-overview\"\u003eProject Overview\u003c/h2\u003e\n\u003cp\u003eIn this opportunity we\u0026rsquo;ll go over a project developed through the combination of Google Earth Engine and Node.js once again. Data we\u0026rsquo;ll be retrieved  and processed through GEE Python API and afterwards served to a local website interface using Node.js\u003c/p\u003e\n\u003cp\u003eWe’ll walk through:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRetrieving and processing data from Google Earth Engine using Python,\u003c/li\u003e\n\u003cli\u003eserving this data through a local Node.js server and,\u003c/li\u003e\n\u003cli\u003ebuilding a responsive dashboard for data visualization.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy the end of this project, you’ll learn how to integrate these powerful tools to visualize complex geospatial datasets in real time. The project is reproducible and available on my \u003ca href=\"https://github.com/jm-marcenaro/Visualizador-GOES\" target=\"_blank\" rel=\"noopener\"\u003eGithub repository\u003c/a\u003e so you can follow along.\u003c/p\u003e","tags":null,"title":"GOES Visualizer"},{"categories":null,"contents":"Project Overview In this opportunity we\u0026rsquo;ll go over a project developed through the combination of Google Earth Engine and Node.js. Data we\u0026rsquo;ll be retrieved and processed through GEE Python API and afterwards served to a local dashboard using Node.js\nWe’ll walk through:\nRetrieving and processing data from Google Earth Engine using Python, serving this data through a local Node.js server and, building a responsive dashboard for data visualization. By the end of this project, you’ll learn how to integrate these powerful tools to visualize complex geospatial datasets in real time. The project is reproducible and available on my Github repository so you can follow along.\nHere’s a preview of the final dashboard. It features a table and several time series plots that display forecast data for multiple climatic variables in the city of Buenos Aires.\nProject structure The project structure is shown below. The main directories are:\nDB: Contains the Python script that retrieves and stores data from GEE, along with the database file itself. public: Contains the HTML structure, JavaScript for interactivity, and CSS for styling. /. │ ├── DB/ │ ├── DBS-BD-LOG.txt # Log file │ ├── GFS-DB.bat # Batch script for DB │ ├── GFS-DB.db # Database file │ ├── GFS-DB.py # Python script for DB │ ├── GFS-DB.vbs # VBS script for DB │ ├── images/ ├── node_modules/ ├── public/ │ ├── style/ # CSS styles │ ├── index.html # Main HTML file │ ├── plot.js # JavaScript for plotting data │ ├── table.js # JavaScript for table functionality │ ├── package.json ├── package-lock.json ├── README.md ├── server.bat ├── server.js # Node.js server ├── server.vbs # Triggers the server through the task scheduler Retrieving data from GEE Python API Shortly, the Python script GFS-DB.py retrieves the latest available weather forecast data for Buenos Aires from Google Earth Engine, processes it, and stores the results in a SQLite database. I’ve previously written more about this dataset, which you can check out here.\nThe script starts by defining the region of interest and collects weather data (temperature, humidity, wind speed, direction, cloud cover, and precipitation) for the next 120 hours.\nUsing the XEE library (learn more here), the weather data is processed into a more usable format and organized into a pandas DataFrame. The final output is stored in a SQLite database, making it easily accessible for future use by the server.\nAdditionally, logging is included to track the process, and the Python script is automatically triggered every 3 hours via Windows Task Scheduler (or a cron job in Linux).\nServing through a local Node.js server The server.js script initializes an Express application to serve static files and interact with the SQLite database GFS-DB.db we\u0026rsquo;ve previously created. It then sets up a GET route at /data to retrieve all records from the database table. Upon success, it responds with a JSON object containing the forecast data. The server listens on a specified port, providing a straightforward API for accessing this data, which can be integrated with the JavaScript code that we\u0026rsquo;ll explore next.\nBuilding a responsive dashboard for data visualization The dashboard is built using a combination of HTML, JavaScript, and CSS. Let’s break it up and explore what each component does:\nHTML The HTML file, index.html, defines the structure and functionality of the dashboard. It includes links to styles and libraries such as jQuery, DataTables, and Chart.js to enhance interactivity and visualization.\nAt the top, a table is created to display weather variables, which will be populated with data through the table.js script. Below the table, various canvas elements are provided for plotting charts, which will also be filled with data via the plot.js file.\nJavascript The table.js script is in charge of populating with data the dashboard table. It uses the Fetch API to asynchronously retrieve data from the server at the /data endpoint.\nThe script formats numerical values for better readability and dynamically constructs table rows and cells to display the weather variables. Besides, it identifies which record is closest to the current date and time. This closest record is highlighted in the table for easy reference.\nOn the other hand, plot.js is responsible for creating dynamic visualizations using Chart.js. Similar to table.js, it fetches data from the server /data endpoint and fills multiple bar charts, each representing a different weather parameter.\nSimilarly, a vertical line displaying the current date and time is created to enhance readibility and provide context.\nFinally, both scripts are set to refresh periodically ensuring that the dashboard reflects the most current weather conditions available.\nCSS The styles.css file contains simple CSS to style the table and arrange the layout of the bar plots into a grid. It ensures the table is easy to read and the charts well-organized.\nConclusion In this project, we integrated Google Earth Engine (GEE) with a Node.js server to create a dashboard that visualizes GFS weather forecast data for Buenos Aires.\nWe began by retrieving, processing, and storing data using the GEE Python API, along with libraries such as XEE, Pandas, and SQLite.\nAfterwards, through the Node.js server, we established a connection to serve this data via a simple API.\nFinally, the dashboard, created with HTML, JavaScript, and CSS, features a dynamic table and multiple bar charts that update automatically to reflect real-time conditions.\nI hope you found this project interesting and remember it’s available on my GitHub repository\n","date":"September 26, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/nodejs/nodejs_1/","summary":"\u003ch2 id=\"project-overview\"\u003eProject Overview\u003c/h2\u003e\n\u003cp\u003eIn this opportunity we\u0026rsquo;ll go over a project developed through the combination of Google Earth Engine and Node.js. Data we\u0026rsquo;ll be retrieved  and processed through GEE Python API and afterwards served to a local dashboard using Node.js\u003c/p\u003e\n\u003cp\u003eWe’ll walk through:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRetrieving and processing data from Google Earth Engine using Python,\u003c/li\u003e\n\u003cli\u003eserving this data through a local Node.js server and,\u003c/li\u003e\n\u003cli\u003ebuilding a responsive dashboard for data visualization.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBy the end of this project, you’ll learn how to integrate these powerful tools to visualize complex geospatial datasets in real time. The project is reproducible and available on my \u003ca href=\"https://github.com/jm-marcenaro/GFS-Dashboard\" target=\"_blank\" rel=\"noopener\"\u003eGithub repository\u003c/a\u003e so you can follow along.\u003c/p\u003e","tags":null,"title":"GFS Dashboard"},{"categories":null,"contents":"Project Overview In this post, we\u0026rsquo;ll explore the correlation between multiple environmental data variables using the Google Earth Engine (GEE) Python API. Specifically, we\u0026rsquo;ll analyze yearly aggregated Normalized Difference Vegetation Index (NDVI), precipitation, and real evapotranspiration (ETr) over a region of interest spanning approximately 5,000 km² and over a five-year period (2019-2023).\nNDVI data will be extracted from the Sentinel-2 satellites. Precipitation data will be sourced from the CHIRPS dataset. Real evapotranspiration (ETr) data will be obtained from the MODIS satellite. To make this project reproducible, you can access all the code from my GitHub repository. Feel free to check it out, try the code yourself, and leave comments or suggestions.\nAnalysis To begin with, we\u0026rsquo;ll import the necessary libraries, initialize earth engine and define our region of interest by reading a shapefile and extracting its bounding box with Geopandas. The region corresponds to a department within Buenos Aires province, Argentina.\n# Libraries import pandas as pd import numpy as np import matplotlib.pyplot as plt from matplotlib.colors import ListedColormap import matplotlib.colors as colors import geopandas as gpd from datetime import datetime, timedelta import ee import urllib.request import rasterio from rasterio.mask import mask import xarray as xr # Initialize EE ee.Initialize() # Read shapefile with geopandas GDF_01 = gpd.read_file(r\u0026#34;GIS/ROI.shp\u0026#34;) # For now, we\u0026#39;ll work with ROI´s bounding box BB_01 = GDF_01.total_bounds # Define coordinates x_min, y_min, x_max, y_max = BB_01 # Create ee.Geometry ROI = ee.Geometry.Rectangle([x_min, y_min, x_max, y_max]) Next, we\u0026rsquo;ll retrieve NDVI data using Sentinel-2’s near-infrared (Band 8) and red (Band 4) bands. We’ll apply a threshold to exclude pixels with more than 25% cloud coverage. The data will cover a 5-year period, from 2019 to 2023.\n# Define years of interest Ys = [2019, 2020, 2021, 2022, 2023] # Define a dictionary of image collections DICT_Cs_01 = {} for Y in Ys: DICT_Cs_01[f\u0026#34;{Y}\u0026#34;] = ee.ImageCollection(\u0026#39;COPERNICUS/S2_SR_HARMONIZED\u0026#39;)\\ .filterBounds(ROI)\\ .filterDate(f\u0026#34;{Y}-01-01\u0026#34;, f\u0026#34;{Y+1}-01-01\u0026#34;)\\ .filter(ee.Filter.lt(\u0026#39;CLOUDY_PIXEL_PERCENTAGE\u0026#39;, 25)) NDVI is not directly available as a band; instead, we need to calculate it by taking the normalized difference between the bands mentioned above. We’ll define a function to compute NDVI and then map it over the image collections we\u0026rsquo;ve defined.\n# Calculate NDVI on every image # Create a function to calculate NDVI def s2_ndvi(image): ndvi = image.normalizedDifference([\u0026#39;B8\u0026#39;, \u0026#39;B4\u0026#39;]).rename(\u0026#39;NDVI\u0026#39;) return image.addBands(ndvi) # Map the function over the ICs for k, C in DICT_Cs_01.items(): DICT_Cs_01[f\u0026#34;{k}\u0026#34;] = C.map(s2_ndvi) Since we are aggregating the data on a yearly basis, we will use the median NDVI value for each pixel. The median is preferred over the mean because it is less sensitive to outliers and provides a more accurate measure of central tendency. To facilitate this, we’ll define a dictionary of images that computes the median NDVI value for each pixel for each year in the analysis.\n# For each year create an image that takes the median NDVI # Dicitonary of images DICT_Is_01 = {} for k, C in DICT_Cs_01.items(): DICT_Is_01[f\u0026#34;{k}\u0026#34;] = C.select(\u0026#39;NDVI\u0026#39;).median() Now we\u0026rsquo;ll download the images locally so that we can read them afterwards with the library Rasterio. This library will enable us to compute statistics over the images and the ability to create figures out of them. Note that we used a 500-meter scale, as the original Sentinel-2 spatial resolution of 10 meters would have required significantly more memory.\n# Download images locally for k, I in DICT_Is_01.items(): FN = f\u0026#34;S2-MED-NDVI-{k}.tif\u0026#34; # Define the export parameters. url = I.getDownloadURL({ \u0026#34;scale\u0026#34; : 500, \u0026#34;crs\u0026#34; : \u0026#34;EPSG:4326\u0026#34;, \u0026#34;region\u0026#34; : ROI, \u0026#34;filePerBand\u0026#34;: False, \u0026#34;format\u0026#34; : \u0026#34;GEO_TIFF\u0026#34; }) # Start downloading urllib.request.urlretrieve(url, fr\u0026#34;Output/{FN}\u0026#34;) print(f\u0026#34;{FN} downloaded!\u0026#34;) We will now read the images using Rasterio, define a custom NDVI color palette, and set the parameters for our figures.\n# Read images with rasterio DICT_Rs_01 = {} for Y in Ys: FN = f\u0026#34;S2-MED-NDVI-{Y}.tif\u0026#34; DICT_Rs_01[f\u0026#34;{Y}\u0026#34;] = rasterio.open(fr\u0026#34;Output/{FN}\u0026#34;) # Create NDVI palette ndvi_palette_hex = [\u0026#39;FFFFFF\u0026#39;, \u0026#39;CE7E45\u0026#39;, \u0026#39;DF923D\u0026#39;, \u0026#39;F1B555\u0026#39;, \u0026#39;FCD163\u0026#39;, \u0026#39;99B718\u0026#39;, \u0026#39;74A901\u0026#39;, \u0026#39;66A000\u0026#39;, \u0026#39;529400\u0026#39;, \u0026#39;3E8601\u0026#39;, \u0026#39;207401\u0026#39;, \u0026#39;056201\u0026#39;, \u0026#39;004C00\u0026#39;, \u0026#39;023B01\u0026#39;, \u0026#39;012E01\u0026#39;, \u0026#39;011D01\u0026#39;, \u0026#39;011301\u0026#39;] ndvi_palette_rgba = [colors.hex2color(\u0026#39;#\u0026#39; + hex_color) for hex_color in ndvi_palette_hex] ndvi_palette = ListedColormap(ndvi_palette_rgba) # Figure parameters # Width, height W, H = 4, 2.5 # Aspect ratio AR = W/H # Set figure bounds Bs = DICT_Rs_01[\u0026#34;2019\u0026#34;].bounds # Set fontsizes T_FS = 14 AX_FS = 12 We are now ready to use Matplotlib and create our first figure:\nfig, axs = plt.subplots(1, 5, figsize=(5*W, H), constrained_layout=True) for (k, R), ax in zip(DICT_Rs_01.items(), axs.ravel()): _ = ax.imshow(R.read(1), vmin=0.25, vmax=0.75, cmap=ndvi_palette, aspect=1/AR, extent=(Bs.left, Bs.right, Bs.bottom, Bs.top)) ax.set_title(f\u0026#34;Median NDVI {k}\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) GDF_01.plot(ax=ax, facecolor=\u0026#34;none\u0026#34;, edgecolor=\u0026#34;black\u0026#34;, zorder=2, linewidth=2, alpha=1) ax.axis(\u0026#34;off\u0026#34;) CB = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(0.25, .80, .05), shrink=.75) CB.ax.tick_params(labelsize=AX_FS) CB.set_label(\u0026#34;[%]\u0026#34;, fontsize=AX_FS) plt.savefig(r\u0026#34;Output/_01.png\u0026#34;) plt.show(); We are now ready to move on to our next variable: precipitation. For this, we will use the CHIRPS product, which provides daily precipitation values with a spatial resolution of approximately 5000 meters.\nSimilarly to what we did before, we\u0026rsquo;ll define a dictionary of image collections, one for each year.\n# Define a dictionary of image collections DICT_Cs_02 = {} for Y in Ys: DICT_Cs_02[f\u0026#34;{Y}\u0026#34;] = ee.ImageCollection(\u0026#34;UCSB-CHG/CHIRPS/DAILY\u0026#34;)\\ .filterBounds(ROI)\\ .filterDate(f\u0026#34;{Y}-01-01\u0026#34;, f\u0026#34;{Y+1}-01-01\u0026#34;) Since we are aggregating data yearly, we will compute the cumulative sum of precipitation at pixel level. To accomplish this, we\u0026rsquo;ll define a new dictionary of images that calculates the annual sum for each pixel and year.\n# Define new dictionary of images with the cumulative sum for each year DICT_Is_02 = {} for k, C in DICT_Cs_02.items(): DICT_Is_02[k] = C.sum() As we did before, we\u0026rsquo;ll download images locally. This time we\u0026rsquo;ll use the original spatial resolution.\n# Get spatial resolution OS_02 = DICT_Cs_02[\u0026#34;2019\u0026#34;].select(\u0026#34;precipitation\u0026#34;).first().projection().nominalScale().getInfo() # Download images locally for k, I in DICT_Is_02.items(): FN = f\u0026#34;CHIRPS-AC-PPT-{k}.tif\u0026#34; # Define the export parameters. url = I.getDownloadURL({ \u0026#34;scale\u0026#34; : OS_02, \u0026#34;crs\u0026#34; : \u0026#34;EPSG:4326\u0026#34;, \u0026#34;region\u0026#34; : ROI, \u0026#34;filePerBand\u0026#34;: False, \u0026#34;format\u0026#34; : \u0026#34;GEO_TIFF\u0026#34; }) # Start downloading urllib.request.urlretrieve(url, fr\u0026#34;Output/{FN}\u0026#34;) print(f\u0026#34;{FN} downloaded!\u0026#34;) Once we\u0026rsquo;ve written the images to disk we\u0026rsquo;ll read them with Rasterio as we previously did.\n# Read images with rasterio DICT_Rs_02 = {} for Y in Ys: FN = f\u0026#34;CHIRPS-AC-PPT-{Y}.tif\u0026#34; DICT_Rs_02[f\u0026#34;{Y}\u0026#34;] = rasterio.open(fr\u0026#34;Output/{FN}\u0026#34;) And we are now ready to use Matplotlib and create our second figure:\nfig, axs = plt.subplots(1, 5, figsize=(5*W, H), constrained_layout=True) for (k, R), ax in zip(DICT_Rs_02.items(), axs.ravel()): _ = ax.imshow(R.read(1), vmin=500, vmax=1000, cmap=\u0026#34;Blues\u0026#34;, aspect=1/AR, extent=(Bs.left, Bs.right, Bs.bottom, Bs.top)) ax.set_title(f\u0026#34;Cumulated PPT {k}\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) GDF_01.plot(ax=ax, facecolor=\u0026#34;none\u0026#34;, edgecolor=\u0026#34;black\u0026#34;, zorder=2, linewidth=2, alpha=1) ax.axis(\u0026#34;off\u0026#34;) CB = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(500, 1050, 50), shrink=.75) CB.ax.tick_params(labelsize=AX_FS) CB.set_label(\u0026#34;[mm]\u0026#34;, fontsize=AX_FS) plt.savefig(r\u0026#34;Output/_02.png\u0026#34;) plt.show(); Finally, we\u0026rsquo;ll get real evapotranspiration values from MODIS. See more on this product here.\nWe\u0026rsquo;ll start by defining a dictionary of image collections. Note we\u0026rsquo;ve scaled data by 0.1 as indicated in the documentation.\n# Define a dictionary of image collections DICT_Cs_03 = {} for Y in Ys: DICT_Cs_03[f\u0026#34;{Y}\u0026#34;] = ee.ImageCollection(\u0026#34;MODIS/061/MOD16A2GF\u0026#34;)\\ .filterBounds(ROI)\\ .filterDate(f\u0026#34;{Y}-01-01\u0026#34;, f\u0026#34;{Y+1}-01-01\u0026#34;)\\ .map(lambda i: i.select(\u0026#39;ET\u0026#39;).multiply(0.1)) Evapotranspiration values are provided as cumulative sums over 8-day periods. Since we are aggregating the data on a yearly basis, we will calculate the cumulative sum of evapotranspiration for each year. To achieve this, we\u0026rsquo;ll define another dictionary of images, just as we did for the other variables.\n# For each year create an image that takes the sum of ET # Dictionary of images DICT_Is_03 = {} for k, C in DICT_Cs_03.items(): DICT_Is_03[f\u0026#34;{k}\u0026#34;] = C.select(\u0026#39;ET\u0026#39;).sum() As we did before, we\u0026rsquo;ll use the product\u0026rsquo;s spatial resolution, which is approximately 500 meters, and download the images locally.\n# Get spatial resolution OS_03 = DICT_Cs_03[\u0026#34;2019\u0026#34;].select(\u0026#34;ET\u0026#34;).first().projection().nominalScale().getInfo() # Download images locally for k, I in DICT_Is_03.items(): FN = f\u0026#34;MODIS-ETR-{k}.tif\u0026#34; # Define the export parameters. url = I.getDownloadURL({ \u0026#34;scale\u0026#34; : OS_03, \u0026#34;crs\u0026#34; : \u0026#34;EPSG:4326\u0026#34;, \u0026#34;region\u0026#34; : ROI, \u0026#34;filePerBand\u0026#34;: False, \u0026#34;format\u0026#34; : \u0026#34;GEO_TIFF\u0026#34; }) # Start downloading urllib.request.urlretrieve(url, fr\u0026#34;Output/{FN}\u0026#34;) print(f\u0026#34;{FN} downloaded!\u0026#34;) We read images with Rasterio:\n# Read images with rasterio DICT_Rs_03 = {} for Y in Ys: FN = f\u0026#34;MODIS-ETR-{Y}.tif\u0026#34; DICT_Rs_03[f\u0026#34;{Y}\u0026#34;] = rasterio.open(fr\u0026#34;Output/{FN}\u0026#34;) And we plot them using Matplotlib:\nfig, axs = plt.subplots(1, 5, figsize=(5*W, H), constrained_layout=True) for (k, R), ax in zip(DICT_Rs_03.items(), axs.ravel()): _ = ax.imshow(R.read(1), vmin=250, vmax=1000, cmap=\u0026#34;Greens\u0026#34;, aspect=1/AR, extent=(Bs.left, Bs.right, Bs.bottom, Bs.top)) ax.set_title(f\u0026#34;Cumulated ETR {k}\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) GDF_01.plot(ax=ax, facecolor=\u0026#34;none\u0026#34;, edgecolor=\u0026#34;black\u0026#34;, zorder=2, linewidth=2, alpha=1) ax.axis(\u0026#34;off\u0026#34;) CB = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(200, 1100, 100), shrink=.75) CB.ax.tick_params(labelsize=AX_FS) CB.set_label(\u0026#34;[mm]\u0026#34;, fontsize=AX_FS) plt.savefig(r\u0026#34;Output/_03.png\u0026#34;) plt.show(); We are now ready to summarize all our data and visualize it together to examine how these variables correlate and the impact they had each year.\nfig, axs = plt.subplots(3, 5, figsize=(5*W, 3*H), constrained_layout=True) for (k, R), ax in zip(DICT_Rs_01.items(), axs.ravel()[:5]): _ = ax.imshow(R.read(1), vmin=0.25, vmax=0.75, cmap=ndvi_palette, aspect=1/AR, extent=(Bs.left, Bs.right, Bs.bottom, Bs.top)) ax.set_title(f\u0026#34;Median NDVI {k}\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) GDF_01.plot(ax=ax, facecolor=\u0026#34;none\u0026#34;, edgecolor=\u0026#34;black\u0026#34;, zorder=2, linewidth=2, alpha=1) ax.axis(\u0026#34;off\u0026#34;) # Annotate with mean value ax.text(0.1, 0.1, f\u0026#34;{R.read(1).mean():.2f} %\u0026#34;, transform=ax.transAxes, ha=\u0026#34;center\u0026#34;, va=\u0026#34;center\u0026#34;, color=\u0026#34;black\u0026#34;, fontsize=10, bbox=dict(facecolor=\u0026#39;pink\u0026#39;, alpha=0.75)) CB = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(0.25, .80, .05), shrink=.75) CB.ax.tick_params(labelsize=AX_FS) CB.set_label(\u0026#34;[%]\u0026#34;, fontsize=AX_FS) for (k, R), ax in zip(DICT_Rs_02.items(), axs.ravel()[5:10]): _ = ax.imshow(R.read(1), vmin=500, vmax=1000, cmap=\u0026#34;Blues\u0026#34;, aspect=1/AR, extent=(Bs.left, Bs.right, Bs.bottom, Bs.top)) ax.set_title(f\u0026#34;Cumulated PPT {k}\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) GDF_01.plot(ax=ax, facecolor=\u0026#34;none\u0026#34;, edgecolor=\u0026#34;black\u0026#34;, zorder=2, linewidth=2, alpha=1) ax.axis(\u0026#34;off\u0026#34;) # Annotate with mean value ax.text(0.1, 0.1, f\u0026#34;{R.read(1).mean():.0f} mm\u0026#34;, transform=ax.transAxes, ha=\u0026#34;center\u0026#34;, va=\u0026#34;center\u0026#34;, color=\u0026#34;black\u0026#34;, fontsize=10, bbox=dict(facecolor=\u0026#39;pink\u0026#39;, alpha=0.75)) CB = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(500, 1050, 50), shrink=.75) CB.ax.tick_params(labelsize=AX_FS) CB.set_label(\u0026#34;[mm]\u0026#34;, fontsize=AX_FS) for (k, R), ax in zip(DICT_Rs_03.items(), axs.ravel()[10:15]): _ = ax.imshow(R.read(1), vmin=250, vmax=1000, cmap=\u0026#34;Greens\u0026#34;, aspect=1/AR, extent=(Bs.left, Bs.right, Bs.bottom, Bs.top)) ax.set_title(f\u0026#34;Cumulated ETR {k}\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) GDF_01.plot(ax=ax, facecolor=\u0026#34;none\u0026#34;, edgecolor=\u0026#34;black\u0026#34;, zorder=2, linewidth=2, alpha=1) ax.axis(\u0026#34;off\u0026#34;) # Annotate with mean value ax.text(0.1, 0.1, f\u0026#34;{R.read(1).mean():.0f} mm\u0026#34;, transform=ax.transAxes, ha=\u0026#34;center\u0026#34;, va=\u0026#34;center\u0026#34;, color=\u0026#34;black\u0026#34;, fontsize=10, bbox=dict(facecolor=\u0026#39;pink\u0026#39;, alpha=0.75)) CB = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(200, 1100, 100), shrink=.75) CB.ax.tick_params(labelsize=AX_FS) CB.set_label(\u0026#34;[mm]\u0026#34;, fontsize=AX_FS) plt.savefig(r\u0026#34;Output/_04.png\u0026#34;) plt.show(); Note we\u0026rsquo;ve added the main value over the region as text in the lower left corner. Anyway it would be more informative if we see can see it this way:\nConclusion As observed, variations in precipitation, real evapotranspiration, and NDVI tend to correlate and move together as expected. This approach not only facilitates year-over-year comparisons but also helps detect spatial trends and identify areas with varying levels of severity.\nIn summary, we successfully processed satellite data for NDVI, precipitation, and real evapotranspiration using various products and techniques. This analysis provided valuable insights into the region and period of interest.\n","date":"September 2, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/gee/ndvi-ppt-etr/ndvi-ppt-etr_1/","summary":"\u003ch3 id=\"project-overview\"\u003eProject Overview\u003c/h3\u003e\n\u003cp\u003eIn this post, we\u0026rsquo;ll explore the correlation between multiple environmental data variables using the Google Earth Engine (GEE) Python API. Specifically, we\u0026rsquo;ll analyze yearly aggregated Normalized Difference Vegetation Index (NDVI), precipitation, and real evapotranspiration (ETr) over a region of interest spanning approximately 5,000 km² and over a five-year period (2019-2023).\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNDVI data will be extracted from the Sentinel-2 satellites.\u003c/li\u003e\n\u003cli\u003ePrecipitation data will be sourced from the CHIRPS dataset.\u003c/li\u003e\n\u003cli\u003eReal evapotranspiration (ETr) data will be obtained from the MODIS satellite.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTo make this project reproducible, you can access all the code from my \u003ca href=\"https://github.com/jm-marcenaro/GEE-Python-API-NDVI-PPT-ETR\" target=\"_blank\" rel=\"noopener\"\u003eGitHub repository\u003c/a\u003e. Feel free to check it out, try the code yourself, and leave comments or suggestions.\u003c/p\u003e","tags":null,"title":"GEE Python API: NDVI, precipitation and real evapotranspiration"},{"categories":null,"contents":"Project Overview In this tutorial, we\u0026rsquo;ll explore the capabilities of batch processing in QGIS. Batch processing is incredibly helpful for repetitive tasks that can otherwise consume a lot of time and effort. By automating these tasks, you can focus on more important aspects of your project, increasing both efficiency and productivity.\nLet me set up an example where we\u0026rsquo;ll fully leverage the power of batch processing in QGIS.\nCase Example We\u0026rsquo;ve got a set of 12 MODIS land surface temperature (LST) images for an area of interest. These images are in Kelvin degrees, but before we can perform our analysis in Celsius, we need to first scale the temperature values by a factor of 0.02. After scaling, we\u0026rsquo;ll convert the temperatures from Kelvin to Celsius by subtracting 273.\nIf we were to take the regular approach, we would have to open the Raster Calculator in QGIS and perform these operations 12 times, once for each image. However, with QGIS\u0026rsquo;s batch processing tool, we can automate these tasks and handle all 12 images efficiently in one go.\nFirst we\u0026rsquo;ll load the images into QGIS as shown in the picture below:\nTo perform the scaling and conversion, we will use the Raster Calculator. Note that the Raster Calculator in the traditional menu doesn’t support batch processing, so we need to access it through the Processing Toolbox as shown below:\nA window will open up and we will first click on the option \u0026lsquo;Run as Batch Process\u0026rsquo;. Afterwards, we’ll see the following menu:\nOn this menu, we’ll need to fill out a table with the arguments for the process we are applying to each of our layers. We\u0026rsquo;ll describe the necessary arguments for each of these columns:\nReference layer: let’s start by filling up the \u0026lsquo;Reference layer\u0026rsquo; column. If we click on the \u0026lsquo;Select from open layers\u0026rsquo; option, we’ll be able to choose from a list of all the available layers. As a result, the table will be automatically populated with these layers.\nExpression: Since we have numbered the layers, we will define the expression for the first layer, then use the fill down option for the other layers. Afterwards, manually edit each expression to match the corresponding layer name (this is straightforward as we have numbered the layers). The expression I used was the following: (\u0026ldquo;01@1\u0026rdquo;*0.02)-273\nCell size: By consulting layers metadata, we see that the spatial resolution is 0.0083 (expressed in degrees as layers have a geographical CRS), that\u0026rsquo;s aproximately 925 meters at the equator. We’ll use this value and populate each row by using the fill down option again.\nOutput extent: For the first layer we\u0026rsquo;ll click on the three dots and select the \u0026lsquo;Calculate from layer option\u0026rsquo;. Remaining layers we\u0026rsquo;ll be populated with the same value by using the fill down option.\nOutput CRS: we\u0026rsquo;ll choose the same CRS (EPSG: 4326) of the original layers and project and once again fill down to every other row.\nOutput: Finally, it only remains to define the output for each layer. Click on the three dots for the first layer, set up a prefix (such as C_), and then click on the \u0026lsquo;Fill with numbers\u0026rsquo; option.\nAs a result of all the steps we\u0026rsquo;ve described above, the completed table should look like the picture shown below:\nDont forget to check the \u0026lsquo;Load layers on completion\u0026rsquo; option to visualize your result upon completion!\nWe are now set up to execute the batch process. Click on Run, and if everything works correctly, no warnings should appear in the console. As a result, new layers should appear in the Layers panel, containing the converted temperatures from Kelvin to Celsius.\nConclusion Batch processing might seem daunting at first, but once you get the hang of it, it can be incredibly useful. Understanding the logic behind setting it up will make you more effective and help reduce repetitive and exhausting tasks. I hope this tutorial has been helpful. Stay tuned for more tutorials!\n","date":"August 20, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/qgis/qgis_1/","summary":"\u003ch2 id=\"project-overview\"\u003eProject Overview\u003c/h2\u003e\n\u003cp\u003eIn this tutorial, we\u0026rsquo;ll explore the capabilities of batch processing in QGIS. Batch processing is incredibly helpful for repetitive tasks that can otherwise consume a lot of time and effort. By automating these tasks, you can focus on more important aspects of your project, increasing both efficiency and productivity.\u003c/p\u003e\n\u003cp\u003eLet me set up an example where we\u0026rsquo;ll fully leverage the power of batch processing in QGIS.\u003c/p\u003e\n\u003ch2 id=\"case-example\"\u003eCase Example\u003c/h2\u003e\n\u003cp\u003eWe\u0026rsquo;ve got a set of 12 MODIS land surface temperature (LST) images for an area of interest. These images are in Kelvin degrees, but before we can perform our analysis in Celsius, we need to first scale the temperature values by a factor of 0.02. After scaling, we\u0026rsquo;ll convert the temperatures from Kelvin to Celsius by subtracting 273.\u003c/p\u003e","tags":null,"title":"QGIS: Batch Processing"},{"categories":null,"contents":"Project Overview In this post, we continue our exploration of the 2023 severe drought in Buenos Aires province, Argentina. In our previous post, we used the CHIRPS dataset to analyze the extent and impact of the drought. Now, we’ll take our analysis a step further by extracting time series data from specific coordinates within the affected region.\nTo ensure that you can follow along and reproduce the results, all the code used in this analysis is available in my GitHub repository.\nAnalysis We\u0026rsquo;ll start by calling the necessary libraries, initializing GEE, and setting our point of interest—specifically chosen for experiencing the most severe drought conditions during this period.\n# Libraries import pandas as pd import numpy as np import matplotlib.pyplot as plt import ee from tqdm import tqdm # Initialize earth engine ee.Initialize() # Define POI (coordinates of interest) POI = ee.Geometry.Point([-60.92069,-34.57511]) Next up, we\u0026rsquo;ll define a dictionary of image collections, one for each year in the 1981-2023 period. Since we’re working with a point object, the code will return only the values associated with the nearest pixel.\n# Create a dictionary of image collections (one for every year) DICT_CHIRPS_01 = {} for YEAR in range (1981, 2024): DATE_START = f\u0026#34;{YEAR}-01-01\u0026#34; DATE_END = f\u0026#34;{YEAR+1}-01-01\u0026#34; DICT_CHIRPS_01[f\u0026#34;{YEAR}\u0026#34;] = ee.ImageCollection(\u0026#34;UCSB-CHG/CHIRPS/DAILY\u0026#34;) \\ .filterBounds(POI) \\ .filterDate(DATE_START, DATE_END) In the following step, we\u0026rsquo;ll calculate the mean over the POI (even though it’s a single pixel) and append the daily precipitation values to a dictionary of lists, one for each year.\n# Store daily precipitation for each year DICT_CHIRPS_02 = {} # Get spatial resolution OS = DICT_CHIRPS_01[\u0026#34;1981\u0026#34;].first().projection().nominalScale().getInfo() for k, IC in tqdm(DICT_CHIRPS_01.items()): # Compute daily ppt on every image _ = IC.map(lambda image: image.set(\u0026#39;precipitation\u0026#39;,\\ image.reduceRegion(reducer=ee.Reducer.mean(), geometry=POI, scale=OS)\\ .get(\u0026#39;precipitation\u0026#39;) )) # Daily ppt to list P_L = _.aggregate_array(\u0026#39;precipitation\u0026#39;).getInfo() DICT_CHIRPS_02[f\u0026#34;{k}\u0026#34;] = P_L With this dictionary, we’ll then create another dictionary of pandas DataFrames. Each DataFrame will contain daily and cumulative precipitation values for each year.\n# Turn each list into a dataframe DICT_CHIRPS_03 = {} for k, L in DICT_CHIRPS_02.items(): DICT_CHIRPS_03[f\u0026#34;{k}\u0026#34;] = pd.DataFrame(data={\u0026#34;PPT\u0026#34; : L}) # Calculate cumultive PPT DICT_CHIRPS_03[f\u0026#34;{k}\u0026#34;][\u0026#34;CUM\u0026#34;] = DICT_CHIRPS_03[f\u0026#34;{k}\u0026#34;][\u0026#34;PPT\u0026#34;].cumsum() Finally, we can now visualize the results to compare precipitation trends throughout the year and assess the severity of the 2023 drought scenario against historical records.\n# Plot cumulative precipitation of every year fig, ax = plt.subplots(figsize=(15, 5)) for k, DF in DICT_CHIRPS_03.items(): if k != \u0026#34;2023\u0026#34;: ax.plot(DF[\u0026#34;CUM\u0026#34;], c=\u0026#34;gray\u0026#34;, alpha=.4) else: ax.plot(DF[\u0026#34;CUM\u0026#34;], c=\u0026#34;firebrick\u0026#34;, linewidth=2, linestyle=\u0026#34;dashed\u0026#34;, label=\u0026#34;2023\u0026#34;) ax.set_title(\u0026#34;CHIRPS - Cumulative Rainfall at POI (1981-2023)\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=14) ax.set_ylabel(\u0026#34;[mm]\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=14) ax.set_xlabel(\u0026#34;Day of year\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=14) ax.grid(alpha=.5) ax.set_ylim(0, 2000) ax.set_xlim(0, 365) ax.set_xticks(range(0, 360+10, 10)) ax.tick_params(which=\u0026#34;both\u0026#34;, labelsize=12) ax.tick_params(axis=\u0026#39;x\u0026#39;, rotation=-90) _, = plt.plot([], [], label=\u0026#34;Remaining years\u0026#34;, linestyle=\u0026#39;-\u0026#39;, color=\u0026#39;gray\u0026#39;, alpha=.4) plt.legend(handles=[_], loc=\u0026#34;upper left\u0026#34;) ax.legend(loc=\u0026#34;upper left\u0026#34;, fontsize=12) fig.tight_layout() plt.show(); Conclusion As observed, the year started with precipitation values within the expected range. However, around day 80, drought conditions began to develop and persisted throughout the year, culminating in the most severe drought recorded during this period.\nThe mean annual rainfall for the entire period from 1981 to 2023 is 1029.3 mm. In contrast, the total rainfall for 2023 was only 701.1 mm—approximately 300 mm less than the average. This significant deficit in precipitation had severe implications for agriculture, making it crucial to quantify these values to understand and assess the impact on crop yields.\nThis post marks the end of our series on analyzing the 2023 severe drought in Buenos Aires province using the CHIRPS dataset. We specifically focused on a set of coordinates where the drought\u0026rsquo;s impact was most severe. Leveraging the capabilities of the GEE Python API, along with tools like Geopandas, Rasterio, and Matplotlib, we thoroughly examined and visualized the data.\n","date":"August 15, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/gee/chirps/chirps_2/","summary":"\u003ch3 id=\"project-overview\"\u003eProject Overview\u003c/h3\u003e\n\u003cp\u003eIn this post, we continue our exploration of the 2023 severe drought in Buenos Aires province, Argentina. In our previous post, we used the CHIRPS dataset to analyze the extent and impact of the drought. Now, we’ll take our analysis a step further by extracting time series data from specific coordinates within the affected region.\u003c/p\u003e\n\u003cp\u003eTo ensure that you can follow along and reproduce the results, all the code used in this analysis is available in my \u003ca href=\"https://github.com/jm-marcenaro/GEE-Python-API-CHIRPS\" target=\"_blank\" rel=\"noopener\"\u003eGitHub repository\u003c/a\u003e.\u003c/p\u003e","tags":null,"title":"GEE Python API and CHIRPS: Analyzing precipitation in Buenos Aires - Part 2"},{"categories":null,"contents":"Project Overview Welcome back! In this post, we\u0026rsquo;ll delve into the severe drought that affected Buenos Aires Province in Argentina, in 2023, using the CHIRPS dataset and the Google Earth Engine (GEE) Python API.\nAs detailed in the GEE catalog, CHIRPS—short for Climate Hazards Group InfraRed Precipitation with Station data—is a 30+ year quasi-global rainfall dataset. This dataset integrates satellite imagery with in-situ station data at a 0.05° resolution to generate gridded rainfall at daily temporal resolution. This dataset is invaluable for trend analysis and seasonal drought monitoring.\nBy the end of this article, we’ll produce a series of maps showcasing:\nThe annual cumulative precipitation for the year of interest.\nThe mean annual cumulative precipitation for the entire CHIRPS record.\nAn anomaly map highlighting the difference between the first two maps.\nTo ensure this project is reproducible, all the code is available in my GitHub repository. Feel free to explore, run the code, and share your thoughts or suggestions!\nAnalysis We\u0026rsquo;ll begin by importing the necessary libraries, initializing Earth Engine, defining the region of interest (ROI), and creating a dictionary to store the image collections for our analysis. This dictionary will contain an image collection for each year. Keep in mind that the CHIRPS dataset provides daily precipitation values with a spatial resolution of approximately 5000 meters.\n# Libraries import pandas as pd import numpy as np import matplotlib.pyplot as plt from matplotlib.colors import ListedColormap import matplotlib.colors as colors import geopandas as gpd from datetime import datetime, timedelta import ee import urllib.request import rasterio from rasterio.mask import mask import xarray as xr # Initialize earth engine ee.Initialize() # Read Pvcia. Buenos Aires\u0026#39; shapefile GDF_01 = gpd.read_file(r\u0026#34;GIS/pvcia_bs_as_4326.shp\u0026#34;) # For now, we\u0026#39;ll work with Pvcia. Bs. As\u0026#39; bounding box BB_01 = GDF_01.total_bounds # Define coordinates x_min, y_min, x_max, y_max = BB_01 # Create ee.Geometry ROI = ee.Geometry.Rectangle([x_min, y_min, x_max, y_max]) # Create a dictionary of image collections (one for every year) DICT_CHIRPS_01 = {} for YEAR in range (1981, 2024): DATE_START = f\u0026#34;{YEAR}-01-01\u0026#34; DATE_END = f\u0026#34;{YEAR+1}-01-01\u0026#34; DICT_CHIRPS_01[f\u0026#34;{YEAR}\u0026#34;] = ee.ImageCollection(\u0026#34;UCSB-CHG/CHIRPS/DAILY\u0026#34;) \\ .filterBounds(ROI) \\ .filterDate(DATE_START, DATE_END) Next, we\u0026rsquo;ll create a new dictionary that stores the annual cumulative precipitation for each year. This will involve summing up the daily precipitation values within each year\u0026rsquo;s image collection.\n# Define new dictionary of images with the cumulative sum of each year DICT_CHIRPS_02 = {} for k, C in DICT_CHIRPS_01.items(): DICT_CHIRPS_02[k] = C.sum() To calculate the mean annual precipitation, we first need to create a new image collection that combines all the annual cumulative precipitation images we\u0026rsquo;ve defined previously. Once this collection is assembled, we can compute the mean annual precipitation by taking the average of all the images in the collection. Here\u0026rsquo;s how you can do it:\n# Create new image collection containin the images we\u0026#39;ve defined before (each pixel we\u0026#39;ll have 43 values, 1 for every year of the analysis) # Create empty image collection CHIRPS_IC_01 = ee.ImageCollection([]) for k, I in DICT_CHIRPS_02.items(): # Append image to image collection CHIRPS_IC_01 = IC_01.merge(ee.ImageCollection([I])) # Create new image with the mean of the image collection we\u0026#39; ve defined previously CHIRPS_I_01 = CHIRPS_IC_01.mean() Anomaly is then calculated as the difference between the cumulated precipitation of 2023 and the image we\u0026rsquo;ve just created.\n# Calculate the anomaly as the difference between 2023 cumulative precipitation and the mean annual precipitation CHIRPS_AN_2023 = DICT_CHIRPS_02[\u0026#34;2023\u0026#34;].subtract(CHIRPS_I_01) Now that we\u0026rsquo;ve defined the three images we wanted, we can proceed to create our maps. We\u0026rsquo;ll process the images using Rasterio, but first, we need to download the images locally.\n# Get spatial resolution OS = DICT_CHIRPS_01[\u0026#34;2023\u0026#34;].first().projection().nominalScale().getInfo() # Download images locally for I, DESC in zip([CHIRPS_I_01, CHIRPS_AN_2023, DICT_CHIRPS_02[\u0026#34;2023\u0026#34;]], [\u0026#34;HIST\u0026#34;, \u0026#34;ANOM\u0026#34;, \u0026#34;2023\u0026#34;]): FN = f\u0026#34;PPTAC-CHIRPS-BSAS-{DESC}.tif\u0026#34; # Define the export parameters. url = I.getDownloadURL({ \u0026#34;bands\u0026#34; : [\u0026#34;precipitation\u0026#34;], \u0026#34;scale\u0026#34; : OS, \u0026#34;crs\u0026#34; : \u0026#34;EPSG:4326\u0026#34;, \u0026#34;region\u0026#34; : ROI, \u0026#34;filePerBand\u0026#34;: False, \u0026#34;format\u0026#34; : \u0026#34;GEO_TIFF\u0026#34; }) # Start downloading urllib.request.urlretrieve(url, fr\u0026#34;Output/{FN}\u0026#34;) print(f\u0026#34;{FN} downloaded!\u0026#34;) After writing the images to TIFF files, we\u0026rsquo;ll read them and clip them using the Buenos Aires Province shapefile. This will ensure that pixels outside the region of interest are set to NaN. We\u0026rsquo;ll use Rasterio\u0026rsquo;s mask method to accomplish this.\nDICT_Rs_01 = {} for DESC in [\u0026#34;HIST\u0026#34;, \u0026#34;ANOM\u0026#34;, \u0026#34;2023\u0026#34;]: FN = f\u0026#34;PPTAC-CHIRPS-BSAS-{DESC}.tif\u0026#34; DICT_Rs_01[f\u0026#34;{DESC}\u0026#34;] = rasterio.open(fr\u0026#34;Output/{FN}\u0026#34;) # Clip images by Buenos Aires province shapefile DICT_Rs_02 = {} for k, R in DICT_Rs_01.items(): out_image, out_transform = mask(R, GDF_01.geometry, crop=True, nodata=np.nan) # Store the clipped image DICT_Rs_02[f\u0026#34;{k}\u0026#34;] = out_image[0] Next, we\u0026rsquo;ll define custom color palettes for the cumulative precipitation and precipitation anomaly maps. Additionally, we’ll specify parameters for the maps, such as width, height, and bounds. To provide context, we’ll also include a shapefile with Buenos Aires districts.\n# Define palettes # Cumulated PPT palette pp_hex = [\u0026#39;ffffff\u0026#39;, \u0026#39;d9eafd\u0026#39;, \u0026#39;b3d6fb\u0026#39;, \u0026#39;8ec2f9\u0026#39;, \u0026#39;68aef7\u0026#39;, \u0026#39;439af5\u0026#39;, \u0026#39;2186f3\u0026#39;, \u0026#39;0062f1\u0026#39;, \u0026#39;0051d8\u0026#39;, \u0026#39;0040bf\u0026#39;, \u0026#39;0030a6\u0026#39;, \u0026#39;00208d\u0026#39;, \u0026#39;001174\u0026#39;, \u0026#39;00005b\u0026#39;, \u0026#39;000042\u0026#39;] pp_rgba = [colors.hex2color(\u0026#39;#\u0026#39; + hex_color + \u0026#39;FF\u0026#39;) for hex_color in pp_hex] pp_palette = ListedColormap(pp_rgba) # Anomaly PPT palette an_hex = [\u0026#39;a50026\u0026#39;, \u0026#39;d73027\u0026#39;, \u0026#39;f46d43\u0026#39;, \u0026#39;fdae61\u0026#39;, \u0026#39;fee08b\u0026#39;, \u0026#39;ffffff\u0026#39;, \u0026#39;d9ef8b\u0026#39;, \u0026#39;a6d96a\u0026#39;, \u0026#39;66bd63\u0026#39;, \u0026#39;1a9850\u0026#39;, \u0026#39;006837\u0026#39;] an_rgba = [colors.hex2color(\u0026#39;#\u0026#39; + hex_color + \u0026#39;FF\u0026#39;) for hex_color in an_hex] an_palette = ListedColormap(an_rgba) # Define figure parameters # Aspect IMG_RATIO = DICT_Rs_02[\u0026#34;2023\u0026#34;].shape[1] / DICT_Rs_02[\u0026#34;2023\u0026#34;].shape[0] # Define width and height W = 7 H = W * IMG_RATIO # Set figure bounds BOUNDS = DICT_Rs_01[\u0026#34;2023\u0026#34;].bounds # Set fontsizes T_FS = 14 AX_FS = 12 # Read complimentary shapefile with Buenos Aires province districts to add context GDF_02 = gpd.read_file(r\u0026#34;GIS/limites_partidos.shp\u0026#34;) Finally we\u0026rsquo;ll use the parameters we\u0026rsquo;ve defined and create our maps by using matplotlibs capabilities as follows:\nfig, ax = plt.subplots(1, 3, figsize=(3*W, H)) # Mean annual rainfall _ = ax[0].imshow(DICT_Rs_02[\u0026#34;HIST\u0026#34;], vmin=100, vmax=1500, cmap=pp_palette, extent=(BOUNDS.left, BOUNDS.right, BOUNDS.bottom, BOUNDS.top), aspect=1/IMG_RATIO) ax[0].set_title(f\u0026#34;Mean Annual Rainfall (1981 to 2023)\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) CB_0 = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(100, 1600, 100)) # annual rainfall 2023 _ = ax[1].imshow(DICT_Rs_02[\u0026#34;2023\u0026#34;], vmin=100, vmax=1500, cmap=pp_palette, extent=(BOUNDS.left, BOUNDS.right, BOUNDS.bottom, BOUNDS.top), aspect=1/IMG_RATIO) ax[1].set_title(f\u0026#34;Annual Rainfall - 2023\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) CB_1 = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(100, 1600, 100)) # Rainfall anomaly 2023 _ = ax[2].imshow(DICT_Rs_02[\u0026#34;ANOM\u0026#34;], vmin=-300, vmax=300, cmap=an_palette, extent=(BOUNDS.left, BOUNDS.right, BOUNDS.bottom, BOUNDS.top), aspect=1/IMG_RATIO) ax[2].set_title(f\u0026#34;Rainfall Anomaly - 2023\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) CB_2 = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(-400, 450, 50)) for ax, CB in zip(ax.ravel(), [CB_0, CB_1, CB_2]): GDF_01.plot(ax=ax, facecolor=\u0026#34;none\u0026#34;, edgecolor=\u0026#34;black\u0026#34;, zorder=2, linewidth=2.5, alpha=.9) GDF_02.plot(ax=ax, facecolor=\u0026#34;none\u0026#34;, edgecolor=\u0026#34;black\u0026#34;, zorder=2, linewidth=0.75, alpha=.35) ax.axis(\u0026#34;off\u0026#34;) CB.ax.tick_params(labelsize=AX_FS) CB.set_label(\u0026#34;[mm]\u0026#34;, fontsize=AX_FS) fig.tight_layout() plt.savefig(r\u0026#34;Output/_01.png\u0026#34;) plt.show(); Conclusion This post has come to an end. Our analysis provides spatial insights into the most severe drought areas in Buenos Aires Province for 2023, with the most affected region located in the northwest part of the province. We also identified areas that were less affected and observed general patterns by examining the historical record.\nWe utilized the GEE Python API, along with libraries like GeoPandas, Rasterio, and Matplotlib, to achieve this.\nIn our next post, we’ll focus on extracting daily precipitation values from specific coordinates of interest. We will then compare the 2023 time series with historical data to assess the severity of the drought in greater detail.\n","date":"July 30, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/gee/chirps/chirps_1/","summary":"\u003ch3 id=\"project-overview\"\u003eProject Overview\u003c/h3\u003e\n\u003cp\u003eWelcome back! In this post, we\u0026rsquo;ll delve into the severe drought that affected Buenos Aires Province in Argentina, in 2023, using the CHIRPS dataset and the Google Earth Engine (GEE) Python API.\u003c/p\u003e\n\u003cp\u003eAs detailed in the \u003ca href=\"https://developers.google.com/earth-engine/datasets/catalog/UCSB-CHG_CHIRPS_DAILY\" target=\"_blank\" rel=\"noopener\"\u003eGEE catalog\u003c/a\u003e, CHIRPS—short for Climate Hazards Group InfraRed Precipitation with Station data—is a 30+ year quasi-global rainfall dataset. This dataset integrates satellite imagery with in-situ station data at a 0.05° resolution to generate gridded rainfall at daily temporal resolution. This dataset is invaluable for trend analysis and seasonal drought monitoring.\u003c/p\u003e","tags":null,"title":"GEE Python API and CHIRPS: Analyzing precipitation in Buenos Aires - Part 1"},{"categories":null,"contents":"Project Overview Hello again! Welcome to the continuation of our deep dive into precipitation forecasting using the GFS dataset and the GEE Python API. In our previous post, we demonstrated how to use the GEE Python API along with the XEE library (an integration of GEE and xarray) to forecast precipitation for specific coordinates. This time, we’re going to expand our analysis to cover an entire region. Besides, we\u0026rsquo;ll leverage additional libraries such as Geopandas and Cartopy to create comprehensive spatial maps of precipitation forecasts.\nThe code builds upon what we covered earlier. You can find the Jupyter notebook in my GitHub repository here.\nBy the end of this tutorial, we\u0026rsquo;ll have a map of the cumulative precipitation over a region of interest (ROI) for a 5-day period. Additionally, we\u0026rsquo;ll provide the cumulative and discrete hourly precipitation at a specific location (point of interest or POI) within the ROI. This will enable us to not only get values at a specific location but also gain insight into the spatial pattern of the event.\nAnalysis and Visualization In our previous post, we ended up with two objects: DS_01 and DF_01. DS_01 is an xarray dataset containing the discrete and cumulative precipitation for our region of interest (ROI), while DF_01 is a pandas dataframe containing the same variables but specifically for our point of interest (POI).\nAs a result we created a plot of the variables contained within DF_01 that looked like this:\nNow we\u0026rsquo;ll begin by defining a new object named DS_02 that is an xarray object containing the cumulative precipitation for the 5 day period:\n# Create an image that\u0026#39;s the cumulated precipitation for the entire period. DS_02 = DS_01[\u0026#34;CUMSUM\u0026#34;].isel(FyH=-1) - DS_01[\u0026#34;CUMSUM\u0026#34;].isel(FyH=0) Next, we\u0026rsquo;ll define a geodataframe containing the longitude and latitude of our point of interest (POI): # Create a geodataframe with the coordinates of the point of interest # First we define a dataframe and then we turn it into a geodataframe DF_POI = pd.DataFrame({\u0026#39;LON\u0026#39;: [LON], \u0026#39;LAT\u0026#39;: [LAT]}) GDF_POI = gpd.GeoDataFrame(DF_POI, geometry=gpd.points_from_xy(DF_POI[\u0026#34;LON\u0026#34;], DF_POI[\u0026#34;LAT\u0026#34;]), crs=\u0026#34;EPSG:4326\u0026#34;).drop(columns=[\u0026#34;LON\u0026#34;, \u0026#34;LAT\u0026#34;]) Now, we can make our first map with the following code. Note that we are plotting an xarray object by leveraging the integration between xarray and matplotlib. We selected a discrete blues colorbar and set its range and step. Moreover, we took advantage of some of Cartopy\u0026rsquo;s capabilities, such as setting the map projection and adding coastlines for context. Finally, we\u0026rsquo;ve used Geopandas to plot the location of the point of interest (POI) on the map.\nfig, ax = plt.subplots(1, 1, figsize=(5, 5), subplot_kw={\u0026#39;projection\u0026#39;: ccrs.PlateCarree()}, constrained_layout=True) im =DS_02.plot(x=\u0026#34;lon\u0026#34;, y=\u0026#34;lat\u0026#34;, ax=ax, vmin=0, vmax=50, cmap=\u0026#34;Blues\u0026#34;, add_colorbar=False, levels=11) # POI ax.plot(GDF_POI.geometry.x, GDF_POI.geometry.y, \u0026#39;o\u0026#39;, color=\u0026#34;saddlebrown\u0026#34;, markersize=5, markeredgecolor=\u0026#34;black\u0026#34;, label=\u0026#34;POI\u0026#34;) # Add a title to the whole figure ax.set_title(f\u0026#34;Cumulative precipitation forecast\\n{pd.to_datetime(DATE_START):%Y-%m-%d} to {(pd.to_datetime(DATE_START) + timedelta(days=5)):%Y-%m-%d} (UTC-0)\u0026#34;, fontweight=\u0026#39;bold\u0026#39;) # Add land boundaries ax.add_feature(cf.COASTLINE, linewidth=1.5, edgecolor=\u0026#39;black\u0026#39;) # Grid settings GLs = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, x_inline=False, y_inline=False, linewidth=.5, color=\u0026#39;gray\u0026#39;, alpha=0.2, linestyle=\u0026#39;--\u0026#39;) GLs.top_labels = False GLs.right_labels = False # Set x and y ticks at 1-degree intervals using MultipleLocator GLs.xlocator = MultipleLocator(0.5) GLs.ylocator = MultipleLocator(0.5) # Create colorbar with specified ticks cbar = fig.colorbar(im, ax=ax, shrink=0.75) cbar.set_ticks(range(0, 50+5, 5)) cbar.set_label(\u0026#34;[mm]\u0026#34;, rotation=-90, labelpad=10) # Legend ax.legend(loc=\u0026#34;upper right\u0026#34;) # Add a footnote to the bottom left corner fig.text(0.02, 0.10, f\u0026#34;GFS Model (SIM.: {DATE_START})\u0026#34;, color=\u0026#39;gray\u0026#39;) plt.show(); Finally, we\u0026rsquo;ll bring everything together and visualize the map alongside the cumulative and discrete precipitation at the POI. We\u0026rsquo;ll use Matplotlib\u0026rsquo;s GridSpec method to create a well-organized layout. The code is extensive but achieves the desired result effectively.\nHere’s the complete code: # Create the main plot using gridspec fig = plt.figure(figsize=(12, 4.5), constrained_layout=True) GS = fig.add_gridspec(nrows=2, ncols=2, width_ratios=[.5, .75]) # Add a title to the whole figure fig.suptitle(f\u0026#34;Cumulative and hourly precipitation forecast {pd.to_datetime(DATE_START):%Y-%m-%d} to {(pd.to_datetime(DATE_START) + timedelta(days=5)):%Y-%m-%d} (UTC-0)\u0026#34;, fontweight=\u0026#39;bold\u0026#39;) # MAP ax_0 = fig.add_subplot(GS[:, 0], projection=ccrs.PlateCarree()) # ROI im =DS_02.plot(x=\u0026#34;lon\u0026#34;, y=\u0026#34;lat\u0026#34;, ax=ax_0, vmin=0, vmax=50, cmap=\u0026#34;Blues\u0026#34;, add_colorbar=False, levels=11) # POI ax_0.plot(GDF_POI.geometry.x, GDF_POI.geometry.y, \u0026#39;o\u0026#39;, color=\u0026#34;saddlebrown\u0026#34;, markersize=5, markeredgecolor=\u0026#34;black\u0026#34;, label=\u0026#34;POI\u0026#34;) ax_0.set_title(f\u0026#34;Cumulative precipitation over ROI\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) # Add land boundaries ax_0.add_feature(cf.COASTLINE, linewidth=1.5, edgecolor=\u0026#39;black\u0026#39;) # Grid settings GLs = ax_0.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, x_inline=False, y_inline=False, linewidth=.5, color=\u0026#39;gray\u0026#39;, alpha=0.2, linestyle=\u0026#39;--\u0026#39;) # Visibility GLs.top_labels = False GLs.right_labels = False # Set x and y ticks at 1-degree intervals using MultipleLocator GLs.xlocator = MultipleLocator(0.5) GLs.ylocator = MultipleLocator(0.5) # Create colorbar with specified ticks cbar = fig.colorbar(im, ax=ax_0, shrink=0.75) cbar.set_ticks(range(0, 50+5, 5)) cbar.set_label(\u0026#34;[mm]\u0026#34;, rotation=-90, labelpad=10) # Legend ax_0.legend(loc=\u0026#34;upper right\u0026#34;) # Discrete Ppt ax_1 = fig.add_subplot(GS[0, 1]) ax_1.bar(DF_01.index, DF_01[\u0026#34;PPT_D\u0026#34;], label=\u0026#34;Hourly Ppt.\u0026#34;, color=\u0026#34;black\u0026#34;, zorder=5, width=.025) ax_1.set_title(f\u0026#34;Hourly precipitation over POI\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) # Set y range and ticks ax_1.set_ylim(0, 15) ax_1.yaxis.set_ticks(np.arange(0, 15+5, 5)) # Set x ticks to false ax_1.tick_params(labelbottom=False) # Cumulative Ppt ax_2 = fig.add_subplot(GS[1, 1]) ax_2.plot(DF_01.index, DF_01[\u0026#34;CUMSUM\u0026#34;], label=\u0026#34;Cumulative Ppt.\u0026#34;, color=\u0026#34;firebrick\u0026#34;, zorder=5) ax_2.set_title(f\u0026#34;Cumulative precipitation over POI\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) # Set y range and ticks ax_2.set_ylim(0, 50) ax_2.yaxis.set_ticks(np.arange(0, 50+10, 10)) ax_2.tick_params(labelbottom=True) DATE_FMT = mdates.DateFormatter(\u0026#39;%d-%mT%H\u0026#39;) ax_2.xaxis.set_major_formatter(DATE_FMT) ax_2.xaxis.set_major_locator(mdates.HourLocator(byhour=[0, 6, 12, 18])) ax_2.tick_params(axis=\u0026#34;x\u0026#34;, labelrotation=-90) # Common properties for ax in [ax_1, ax_2]: ax.set_ylabel(\u0026#34;[mm]\u0026#34;) ax.legend(loc=\u0026#34;upper left\u0026#34;) ax.grid(alpha=.5) ax.tick_params(axis=\u0026#34;both\u0026#34;, which=\u0026#34;major\u0026#34;) ax.xaxis.set_major_locator(mdates.HourLocator(byhour=[0, 6, 12, 18])) # Add a footnote to the bottom left corner fig.text(0.02, 0.02, f\u0026#34;GFS Model (SIM.: {DATE_START})\u0026#34;, color=\u0026#39;gray\u0026#39;) plt.show(); Conclusion In this post, we\u0026rsquo;ve expanded our initial analysis from specific coordinates to a broader region, allowing us to visualize both the spatial distribution and temporal evolution of precipitation. By leveraging the capabilities of GEE, XEE, and additional libraries such as Geopandas and Cartopy, we\u0026rsquo;ve created a comprehensive map and time series plots that provide a detailed understanding of precipitation forecasts.\n","date":"July 25, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/gee/gfs/gfs_2/","summary":"\u003ch3 id=\"project-overview\"\u003eProject Overview\u003c/h3\u003e\n\u003cp\u003eHello again! Welcome to the continuation of our deep dive into precipitation forecasting using the GFS dataset and the GEE Python API. In our previous post, we demonstrated how to use the GEE Python API along with the XEE library (an integration of GEE and xarray) to forecast precipitation for specific coordinates. This time, we’re going to expand our analysis to cover an entire region. Besides, we\u0026rsquo;ll leverage additional libraries such as Geopandas and Cartopy to create comprehensive spatial maps of precipitation forecasts.\u003c/p\u003e","tags":null,"title":"GEE Python API and Precipitation Forecasting - Part 2"},{"categories":null,"contents":"Project Overview Greetings! Welcome to the first part of a deep dive into Google Earth Engine (GEE) and its Python API. In this series, we\u0026rsquo;ll explore how to leverage the power of GEE for geospatial analysis, focusing on precipitation forecasting using the Global Forecast System (GFS) dataset.\nGFS is a widely-used weather forecast model developed by NOAA. It provides comprehensive weather data, including temperature, wind, and precipitation forecasts, on a global scale. The model delivers forecasts up to 16 days into the future, making it an invaluable tool for a wide range of applications.\nMoreover, we\u0026rsquo;ll explore the newly released XEE library. XEE combines the well-known xarray library with Google Earth Engine, providing powerful tools for handling and analyzing geospatial data. See more about XEE here.\nTo make this project reproducible, you can access all the code from my GitHub repository. Feel free to check it out, try the code yourself, and leave comments or suggestions.\nBy the end of this tutorial, you\u0026rsquo;ll be able to extract a series of precipitation data at 1-hour intervals and calculate cumulative values for a forecast window of 5 days for your coordinates of interest.\nAnalysis To begin with, we\u0026rsquo;ll import the necessary libraries and set our region of interest (ROI). Since I\u0026rsquo;m from Argentina, I\u0026rsquo;ve chosen region from the city I live in, Buenos Aires, as the focus for this analysis.\n# Libraries import ee import pandas as pd import numpy as np import xarray as xr from datetime import datetime, timedelta from tqdm import tqdm import matplotlib.pyplot as plt import matplotlib.dates as mdates ee.Initialize() #ee.Authenticate() isn\u0026#39;t necessary if you\u0026#39;ve your credentials stored. COORDs = [ [-60.09384640, -33.11803785], [-56.61465669, -33.11803785], [-56.61465669, -35.91630163], [-60.09384640, -35.91630163] ] ROI = ee.Geometry.Polygon(COORDs) Now we\u0026rsquo;ll define our dates of interest. I find it relevant to get the accumulated precipitation from the current date onward. For this, we\u0026rsquo;ll select the simulation that starts at T00, which is the initial run of the day. The GFS model performs four simulations daily at 00:00, 06:00, 12:00, and 18:00 UTC. We\u0026rsquo;ll focus on the T00 run to get the forecast data for our analysis. # Select the simulation launched at T00 to obtain the accumulated precipitation for the current day DATE_START = f\u0026#34;{datetime.strftime(datetime.now(), \u0026#39;%Y-%m-%d\u0026#39;)}T00:00\u0026#34; DATE_END = f\u0026#34;{datetime.strftime(datetime.now(), \u0026#39;%Y-%m-%d\u0026#39;)}T06:00\u0026#34; Now we\u0026rsquo;ll create an image collection using the region and dates of interest that we\u0026rsquo;ve defined previously. For more information on this dataset, you can consult the GEE catalog here. Additionally, we\u0026rsquo;ll select the precipitation band and extract the spatial resolution and projection of the data.\nTo facilitate data management and analysis, we\u0026rsquo;ll convert the image collection to an xarray dataset using the XEE library. This conversion allows us to leverage xarray\u0026rsquo;s powerful capabilities for handling multi-dimensional arrays, making it much easier to manipulate and analyze the dataset. C_01 = ee.ImageCollection(\u0026#34;NOAA/GFS0P25\u0026#34;).map(lambda image: image.clip(ROI))\\ .filterDate(DATE_START, DATE_END)\\ .filterMetadata(\u0026#34;forecast_hours\u0026#34;, \u0026#34;greater_than\u0026#34;, 0) # Select band of interest C_01 = C_01.select([\u0026#34;total_precipitation_surface\u0026#34;]) # Get the spatial resolution OS = C_01.first().projection().nominalScale().getInfo() # print(f\u0026#34;Original scale: {OS:.1f} m\u0026#34;) # Get projection data PROJ = C_01.first().select(0).projection() # Turn the image collection object into a xarray dataset DS_01 = xr.open_dataset(C_01, engine=\u0026#39;ee\u0026#39;, crs=\u0026#34;EPSG:4326\u0026#34;, projection=PROJ, geometry=ROI) Now we\u0026rsquo;ll structure our dataset. First, we\u0026rsquo;ll rename the precipitation band to something more descriptive. Next, we\u0026rsquo;ll slice the dataset to include only the first 120 records. This is because GFS data provides hourly frequency forecasts for the first 5 days. For longer-term forecasts, the data shifts to a 3-hour frequency, which we can exclude since we are\u0026rsquo;nt interested.\nAfter defining the initial parameters, we\u0026rsquo;ll create a pandas date range starting from DATE_START and spanning 120 hours with an hourly frequency.\nNext, we update the xarray dataset by assigning our date range FyH as the new temporal coordinate, replacing the original time dimension. We then drop the old time variable and introduce a new data array, FH (forecast hours), which indexes each forecast hour from 1 to 120. This reorganization makes the dataset more intuitive and easier to work with for further analysis and visualization.\n# Rename band DS_01 = DS_01.rename({\u0026#34;total_precipitation_surface\u0026#34; : \u0026#34;PPT\u0026#34;}) # Filter first 120 registers DS_01 = DS_01.isel(time=slice(0, 120)) # Create a pandas daterange starting from DATE_START and spanning 120 hours FyH = pd.date_range(start=DATE_START, freq=\u0026#34;1H\u0026#34;, periods=120+1)[1:] DS_01 = DS_01.assign_coords(FyH=(\u0026#34;time\u0026#34;, FyH)) DS_01 = DS_01.swap_dims({\u0026#34;time\u0026#34; : \u0026#34;FyH\u0026#34;}) DS_01 = DS_01.drop_vars(\u0026#34;time\u0026#34;) DS_01[\u0026#34;FH\u0026#34;] = xr.DataArray(np.arange(1, 121), dims=\u0026#34;FyH\u0026#34;) Now comes a tricky part. GFS data reports precipitation as cumulative values, resetting every 6 hours. To extract hourly precipitation values, we first create a new data array, H, using the modulo operator to identify these 6-hour periods. We then calculate hourly increments by finding the difference between consecutive precipitation values (PPT_D). To handle the 6-hour reset accurately, we use the where method as follows: PPT_D remains unchanged except where the previous H value was zero, in which case PPT_D is set equal to PPT. This ensures correct hourly precipitation data. Finally we compute the cumulative precipitation for the 5 day period. # Modula operator. Possible values are 0, 1, 2, 3, 4 and 5 DS_01[\u0026#34;H\u0026#34;] = DS_01[\u0026#34;FH\u0026#34;] % 6 # One hour increments DS_01[\u0026#34;PPT_D\u0026#34;] = DS_01[\u0026#34;PPT\u0026#34;].diff(dim=\u0026#34;FyH\u0026#34;) # PPT_D remains the same except where the previous H value was equal to 0 DS_01[\u0026#34;PPT_D\u0026#34;] = DS_01[\u0026#34;PPT_D\u0026#34;].where(DS_01[\u0026#34;H\u0026#34;].shift(FyH=1) != 0, DS_01[\u0026#34;PPT\u0026#34;]) # Calculate cumulative ppt along the FyH dimension DS_01[\u0026#34;CUMSUM\u0026#34;] = DS_01[\u0026#34;PPT_D\u0026#34;].cumsum(dim=\u0026#34;FyH\u0026#34;) Next, and nearing the end, we\u0026rsquo;ll convert the dataset into a Pandas dataframe. Specifically, we\u0026rsquo;ll extract precipitation data for specific coordinates of interest within the region we\u0026rsquo;ve defined previously. This will yield the precipitation data from the nearest pixel in the dataset to the provided coordinates. LON, LAT = -58.46633, -34.59960 DF_01 = DS_01.sel(lon=LON, lat=LAT, method=\u0026#34;nearest\u0026#34;).to_dataframe().drop(columns={\u0026#34;lon\u0026#34;, \u0026#34;lat\u0026#34;}) Visualization As a final step, we\u0026rsquo;ll create a plot to visualize our results using Matplotlib\u0026rsquo;s capabilities. Below is the final piece of code and the corresponding output from our analysis: fig, ax = plt.subplots(2, 1, figsize=(12, 6), gridspec_kw={\u0026#34;height_ratios\u0026#34; : [1, .6]}, sharex=True) ax[0].bar(DF_01.index, DF_01[\u0026#34;PPT_D\u0026#34;], label=\u0026#34;Hourly Ppt.\u0026#34;, color=\u0026#34;black\u0026#34;, zorder=5, width=.025) ax[0].set_title(f\u0026#34;Hourly precipitation forecast - GFS Model (SIM.: {DATE_START})\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) # Set y range and ticks ax[0].set_ylim(0, 15) ax[0].yaxis.set_ticks(np.arange(0, 15+1, 1)) ax[1].plot(DF_01.index, DF_01[\u0026#34;CUMSUM\u0026#34;], label=\u0026#34;Cumulative Ppt.\u0026#34;, color=\u0026#34;firebrick\u0026#34;, zorder=5) ax[1].set_title(f\u0026#34;Cumulative precipitation forecast - GFS Model (SIM.: {DATE_START})\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) # Set y range and ticks ax[1].set_ylim(0, 50) ax[1].yaxis.set_ticks(np.arange(0, 50+10, 10)) # Figure settings along both axis for i in [0, 1]: ax[i].set_ylabel(\u0026#34;[mm]\u0026#34;) ax[i].legend(loc=\u0026#34;upper left\u0026#34;) ax[i].grid(alpha=.5) ax[i].tick_params(labelbottom=True) ax[i].tick_params(axis=\u0026#34;both\u0026#34;, which=\u0026#34;major\u0026#34;) DATE_FMT = mdates.DateFormatter(\u0026#39;%d-%mT%H\u0026#39;) ax[i].xaxis.set_major_formatter(DATE_FMT) ax[i].xaxis.set_major_locator(mdates.HourLocator(byhour=[0, 6, 12, 18])) ax[i].tick_params(axis=\u0026#34;x\u0026#34;, labelrotation=-90) fig.tight_layout() plt.show(); Conclusion Looks like we might be expecting some heavy rain this weekend, so watch out! I hope this tutorial was useful for understanding how to extract and analyze precipitation data using the GFS dataset in Google Earth Engine and its Python API. In our next article, we\u0026rsquo;ll go one step further by creating spatial maps for a broader region, leveraging the full capabilities of the XEE library alongside new tools like Geopandas and Cartopy. Stay tuned!\n","date":"July 15, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/gee/gfs/gfs_1/","summary":"\u003ch3 id=\"project-overview\"\u003eProject Overview\u003c/h3\u003e\n\u003cp\u003eGreetings! Welcome to the first part of a deep dive into Google Earth Engine (GEE) and its Python API. In this series, we\u0026rsquo;ll explore how to leverage the power of GEE for geospatial analysis, focusing on precipitation forecasting using the \u003cstrong\u003eGlobal Forecast System\u003c/strong\u003e (GFS) dataset.\u003c/p\u003e\n\u003cp\u003eGFS is a widely-used weather forecast model developed by NOAA. It provides comprehensive weather data, including temperature, wind, and precipitation forecasts, on a global scale. The model delivers forecasts up to 16 days into the future, making it an invaluable tool for a wide range of applications.\u003c/p\u003e","tags":null,"title":"GEE Python API and Precipitation Forecasting - Part 1"},{"categories":null,"contents":"Go Notes ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/_index.bn/","summary":"\u003ch1 id=\"go-notes\"\u003eGo Notes\u003c/h1\u003e","tags":null,"title":"Go এর নোট সমূহ"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/_index.bn/","summary":"","tags":null,"title":"নোট সমূহ"},{"categories":null,"contents":"Bash Notes ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/bash/_index.bn/","summary":"\u003ch1 id=\"bash-notes\"\u003eBash Notes\u003c/h1\u003e","tags":null,"title":"ব্যাশের নোট সমূহ"}]
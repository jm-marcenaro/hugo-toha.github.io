[{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/basic/_index.bn/","summary":"","tags":null,"title":"Go বেসিক"},{"categories":null,"contents":" Hello World A sample go program is show here.\npackage main import \u0026#34;fmt\u0026#34; func main() { message := greetMe(\u0026#34;world\u0026#34;) fmt.Println(message) } func greetMe(name string) string { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34; } Run the program as below:\n$ go run hello.go Variables Normal Declaration:\nvar msg string msg = \u0026#34;Hello\u0026#34; Shortcut:\nmsg := \u0026#34;Hello\u0026#34; Constants const Phi = 1.618 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/basic/introduction/","summary":" Hello World A sample go program is show here.\npackage main import \u0026#34;fmt\u0026#34; func main() { message := greetMe(\u0026#34;world\u0026#34;) fmt.Println(message) } func greetMe(name string) string { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34; } Run the program as below:\n$ go run hello.go Variables Normal Declaration:\nvar msg string msg = \u0026#34;Hello\u0026#34; Shortcut:\nmsg := \u0026#34;Hello\u0026#34; Constants const Phi = 1.618 ","tags":null,"title":"Introduction"},{"categories":null,"contents":" Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.Println(\u0026#34;Value is\u0026#34;, b) func getPointer () (myPointer *int) { a := 234 return \u0026amp;a a := new(int) *a = 234 Pointers point to a memory location of a variable. Go is fully garbage-collected.\nType Conversion i := 2 f := float64(i) u := uint(i) Slice slice := []int{2, 3, 4} slice := []byte(\u0026#34;Hello\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/basic/types/","summary":"Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.","tags":null,"title":"Basic Types"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/advanced/_index.bn/","summary":"","tags":null,"title":"অ্যাডভান্সড"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) Switch switch day { case \u0026#34;sunday\u0026#34;: // cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default! fallthrough case \u0026#34;saturday\u0026#34;: rest() default: work() } Loop for count := 0; count \u0026lt;= 10; count++ { fmt.Println(\u0026#34;My counter is at\u0026#34;, count) } entry := []string{\u0026#34;Jack\u0026#34;,\u0026#34;John\u0026#34;,\u0026#34;Jones\u0026#34;} for i, val := range entry { fmt.Printf(\u0026#34;At position %d, the character %s is present\\n\u0026#34;, i, val) n := 0 x := 42 for n != x { n := guess() } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/basic/flow-control/","summary":"Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) Switch switch day { case \u0026#34;sunday\u0026#34;: // cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default! fallthrough case \u0026#34;saturday\u0026#34;: rest() default: work() } Loop for count := 0; count \u0026lt;= 10; count++ { fmt.Println(\u0026#34;My counter is at\u0026#34;, count) } entry := []string{\u0026#34;Jack\u0026#34;,\u0026#34;John\u0026#34;,\u0026#34;Jones\u0026#34;} for i, val := range entry { fmt.","tags":null,"title":"Flow Control"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/advanced/files/","summary":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) ","tags":null,"title":"File Manipulation"},{"categories":null,"contents":" Variable NAME=\u0026#34;John\u0026#34; echo $NAME echo \u0026#34;$NAME\u0026#34; echo \u0026#34;${NAME} Condition if [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; fi ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/bash/basic/","summary":" Variable NAME=\u0026#34;John\u0026#34; echo $NAME echo \u0026#34;$NAME\u0026#34; echo \u0026#34;${NAME} Condition if [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; fi ","tags":null,"title":"Bash Variables"},{"categories":null,"contents":"Project Overview Welcome back! In this post, we\u0026rsquo;ll delve into the severe drought that affected Buenos Aires Province in Argentina, in 2023, using the CHIRPS dataset and the Google Earth Engine (GEE) Python API.\nAs detailed in the GEE catalog, CHIRPS—short for Climate Hazards Group InfraRed Precipitation with Station data—is a 30+ year quasi-global rainfall dataset. This dataset integrates satellite imagery with in-situ station data at a 0.05° resolution to generate gridded rainfall at daily temporal resolution. This dataset is invaluable for trend analysis and seasonal drought monitoring.\nBy the end of this article, we’ll produce a series of maps showcasing:\nThe annual cumulative precipitation for the year of interest.\nThe mean annual cumulative precipitation for the entire CHIRPS record.\nAn anomaly map highlighting the difference between the first two maps.\nTo ensure this project is reproducible, all the code is available in my GitHub repository. Feel free to explore, run the code, and share your thoughts or suggestions!\nAnalysis We\u0026rsquo;ll begin by importing the necessary libraries, initializing Earth Engine, defining the region of interest (ROI), and creating a dictionary to store the image collections for our analysis. This dictionary will contain an image collection for each year. Keep in mind that the CHIRPS dataset provides daily precipitation values with a spatial resolution of approximately 5000 meters.\n# Libraries import pandas as pd import numpy as np import matplotlib.pyplot as plt from matplotlib.colors import ListedColormap import matplotlib.colors as colors import geopandas as gpd from datetime import datetime, timedelta import ee import urllib.request import rasterio from rasterio.mask import mask import xarray as xr # Initialize earth engine ee.Initialize() # Read Pvcia. Buenos Aires\u0026#39; shapefile GDF_01 = gpd.read_file(r\u0026#34;GIS/pvcia_bs_as_4326.shp\u0026#34;) # For now, we\u0026#39;ll work with Pvcia. Bs. As\u0026#39; bounding box BB_01 = GDF_01.total_bounds # Define coordinates x_min, y_min, x_max, y_max = BB_01 # Create ee.Geometry ROI = ee.Geometry.Rectangle([x_min, y_min, x_max, y_max]) # Create a dictionary of image collections (one for every year) DICT_CHIRPS_01 = {} for YEAR in range (1981, 2024): DATE_START = f\u0026#34;{YEAR}-01-01\u0026#34; DATE_END = f\u0026#34;{YEAR+1}-01-01\u0026#34; DICT_CHIRPS_01[f\u0026#34;{YEAR}\u0026#34;] = ee.ImageCollection(\u0026#34;UCSB-CHG/CHIRPS/DAILY\u0026#34;) \\ .filterBounds(ROI) \\ .filterDate(DATE_START, DATE_END) Next, we\u0026rsquo;ll create a new dictionary that stores the annual cumulative precipitation for each year. This will involve summing up the daily precipitation values within each year\u0026rsquo;s image collection.\n# Define new dictionary of images with the cumulative sum of each year DICT_CHIRPS_02 = {} for k, C in DICT_CHIRPS_01.items(): DICT_CHIRPS_02[k] = C.sum() To calculate the mean annual precipitation, we first need to create a new image collection that combines all the annual cumulative precipitation images we\u0026rsquo;ve defined previously. Once this collection is assembled, we can compute the mean annual precipitation by taking the average of all the images in the collection. Here\u0026rsquo;s how you can do it:\n# Create new image collection containin the images we\u0026#39;ve defined before (each pixel we\u0026#39;ll have 43 values, 1 for every year of the analysis) # Create empty image collection CHIRPS_IC_01 = ee.ImageCollection([]) for k, I in DICT_CHIRPS_02.items(): # Append image to image collection CHIRPS_IC_01 = IC_01.merge(ee.ImageCollection([I])) # Create new image with the mean of the image collection we\u0026#39; ve defined previously CHIRPS_I_01 = CHIRPS_IC_01.mean() Anomaly is then calculated as the difference between the cumulated precipitation of 2023 and the image we\u0026rsquo;ve just created.\n# Calculate the anomaly as the difference between 2023 cumulative precipitation and the mean annual precipitation CHIRPS_AN_2023 = DICT_CHIRPS_02[\u0026#34;2023\u0026#34;].subtract(CHIRPS_I_01) Now that we\u0026rsquo;ve defined the three images we wanted, we can proceed to create our maps. We\u0026rsquo;ll process the images using Rasterio, but first, we need to download the images locally.\n# Get spatial resolution OS = DICT_CHIRPS_01[\u0026#34;2023\u0026#34;].first().projection().nominalScale().getInfo() # Download images locally for I, DESC in zip([CHIRPS_I_01, CHIRPS_AN_2023, DICT_CHIRPS_02[\u0026#34;2023\u0026#34;]], [\u0026#34;HIST\u0026#34;, \u0026#34;ANOM\u0026#34;, \u0026#34;2023\u0026#34;]): FN = f\u0026#34;PPTAC-CHIRPS-BSAS-{DESC}.tif\u0026#34; # Define the export parameters. url = I.getDownloadURL({ \u0026#34;bands\u0026#34; : [\u0026#34;precipitation\u0026#34;], \u0026#34;scale\u0026#34; : OS, \u0026#34;crs\u0026#34; : \u0026#34;EPSG:4326\u0026#34;, \u0026#34;region\u0026#34; : ROI, \u0026#34;filePerBand\u0026#34;: False, \u0026#34;format\u0026#34; : \u0026#34;GEO_TIFF\u0026#34; }) # Start downloading urllib.request.urlretrieve(url, fr\u0026#34;Output/{FN}\u0026#34;) print(f\u0026#34;{FN} downloaded!\u0026#34;) After writing the images to TIFF files, we\u0026rsquo;ll read them and clip them using the Buenos Aires Province shapefile. This will ensure that pixels outside the region of interest are set to NaN. We\u0026rsquo;ll use Rasterio\u0026rsquo;s mask method to accomplish this.\nDICT_Rs_01 = {} for DESC in [\u0026#34;HIST\u0026#34;, \u0026#34;ANOM\u0026#34;, \u0026#34;2023\u0026#34;]: FN = f\u0026#34;PPTAC-CHIRPS-BSAS-{DESC}.tif\u0026#34; DICT_Rs_01[f\u0026#34;{DESC}\u0026#34;] = rasterio.open(fr\u0026#34;Output/{FN}\u0026#34;) # Clip images by Buenos Aires province shapefile DICT_Rs_02 = {} for k, R in DICT_Rs_01.items(): out_image, out_transform = mask(R, GDF_01.geometry, crop=True, nodata=np.nan) # Store the clipped image DICT_Rs_02[f\u0026#34;{k}\u0026#34;] = out_image[0] Next, we\u0026rsquo;ll define custom color palettes for the cumulative precipitation and precipitation anomaly maps. Additionally, we’ll specify parameters for the maps, such as width, height, and bounds. To provide context, we’ll also include a shapefile with Buenos Aires districts.\n# Define palettes # Cumulated PPT palette pp_hex = [\u0026#39;ffffff\u0026#39;, \u0026#39;d9eafd\u0026#39;, \u0026#39;b3d6fb\u0026#39;, \u0026#39;8ec2f9\u0026#39;, \u0026#39;68aef7\u0026#39;, \u0026#39;439af5\u0026#39;, \u0026#39;2186f3\u0026#39;, \u0026#39;0062f1\u0026#39;, \u0026#39;0051d8\u0026#39;, \u0026#39;0040bf\u0026#39;, \u0026#39;0030a6\u0026#39;, \u0026#39;00208d\u0026#39;, \u0026#39;001174\u0026#39;, \u0026#39;00005b\u0026#39;, \u0026#39;000042\u0026#39;] pp_rgba = [colors.hex2color(\u0026#39;#\u0026#39; + hex_color + \u0026#39;FF\u0026#39;) for hex_color in pp_hex] pp_palette = ListedColormap(pp_rgba) # Anomaly PPT palette an_hex = [\u0026#39;a50026\u0026#39;, \u0026#39;d73027\u0026#39;, \u0026#39;f46d43\u0026#39;, \u0026#39;fdae61\u0026#39;, \u0026#39;fee08b\u0026#39;, \u0026#39;ffffff\u0026#39;, \u0026#39;d9ef8b\u0026#39;, \u0026#39;a6d96a\u0026#39;, \u0026#39;66bd63\u0026#39;, \u0026#39;1a9850\u0026#39;, \u0026#39;006837\u0026#39;] an_rgba = [colors.hex2color(\u0026#39;#\u0026#39; + hex_color + \u0026#39;FF\u0026#39;) for hex_color in an_hex] an_palette = ListedColormap(an_rgba) # Define figure parameters # Aspect IMG_RATIO = DICT_Rs_02[\u0026#34;2023\u0026#34;].shape[1] / DICT_Rs_02[\u0026#34;2023\u0026#34;].shape[0] # Define width and height W = 7 H = W * IMG_RATIO # Set figure bounds BOUNDS = DICT_Rs_01[\u0026#34;2023\u0026#34;].bounds # Set fontsizes T_FS = 14 AX_FS = 12 # Read complimentary shapefile with Buenos Aires province districts to add context GDF_02 = gpd.read_file(r\u0026#34;GIS/limites_partidos.shp\u0026#34;) Finally we\u0026rsquo;ll use the parameters we\u0026rsquo;ve defined and create our maps by using matplotlibs capabilities as follows:\nfig, ax = plt.subplots(1, 3, figsize=(3*W, H)) # Mean annual rainfall _ = ax[0].imshow(DICT_Rs_02[\u0026#34;HIST\u0026#34;], vmin=100, vmax=1500, cmap=pp_palette, extent=(BOUNDS.left, BOUNDS.right, BOUNDS.bottom, BOUNDS.top), aspect=1/IMG_RATIO) ax[0].set_title(f\u0026#34;Mean Annual Rainfall (1981 to 2023)\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) CB_0 = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(100, 1600, 100)) # annual rainfall 2023 _ = ax[1].imshow(DICT_Rs_02[\u0026#34;2023\u0026#34;], vmin=100, vmax=1500, cmap=pp_palette, extent=(BOUNDS.left, BOUNDS.right, BOUNDS.bottom, BOUNDS.top), aspect=1/IMG_RATIO) ax[1].set_title(f\u0026#34;Annual Rainfall - 2023\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) CB_1 = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(100, 1600, 100)) # Rainfall anomaly 2023 _ = ax[2].imshow(DICT_Rs_02[\u0026#34;ANOM\u0026#34;], vmin=-300, vmax=300, cmap=an_palette, extent=(BOUNDS.left, BOUNDS.right, BOUNDS.bottom, BOUNDS.top), aspect=1/IMG_RATIO) ax[2].set_title(f\u0026#34;Rainfall Anomaly - 2023\u0026#34;, fontweight=\u0026#34;bold\u0026#34;, fontsize=T_FS) CB_2 = plt.colorbar(_, extend=\u0026#34;both\u0026#34;, ticks=np.arange(-400, 450, 50)) for ax, CB in zip(ax.ravel(), [CB_0, CB_1, CB_2]): GDF_01.plot(ax=ax, facecolor=\u0026#34;none\u0026#34;, edgecolor=\u0026#34;black\u0026#34;, zorder=2, linewidth=2.5, alpha=.9) GDF_02.plot(ax=ax, facecolor=\u0026#34;none\u0026#34;, edgecolor=\u0026#34;black\u0026#34;, zorder=2, linewidth=0.75, alpha=.35) ax.axis(\u0026#34;off\u0026#34;) CB.ax.tick_params(labelsize=AX_FS) CB.set_label(\u0026#34;[mm]\u0026#34;, fontsize=AX_FS) fig.tight_layout() plt.savefig(r\u0026#34;Output/_01.png\u0026#34;) plt.show(); Conclusion This post has come to an end. Our analysis provides spatial insights into the most severe drought areas in Buenos Aires Province for 2023, with the most affected region located in the northwest part of the province. We also identified areas that were less affected and observed general patterns by examining the historical record.\nWe utilized the GEE Python API, along with libraries like GeoPandas, Rasterio, and Matplotlib, to achieve this.\nIn our next post, we’ll focus on extracting daily precipitation values from specific coordinates of interest. We will then compare the 2023 time series with historical data to assess the severity of the drought in greater detail.\n","date":"July 30, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/chirps/chirps_1/","summary":"Project Overview Welcome back! In this post, we\u0026rsquo;ll delve into the severe drought that affected Buenos Aires Province in Argentina, in 2023, using the CHIRPS dataset and the Google Earth Engine (GEE) Python API.\nAs detailed in the GEE catalog, CHIRPS—short for Climate Hazards Group InfraRed Precipitation with Station data—is a 30+ year quasi-global rainfall dataset. This dataset integrates satellite imagery with in-situ station data at a 0.05° resolution to generate gridded rainfall at daily temporal resolution.","tags":null,"title":"GEE Python API and CHIRPS: Analyzing precipitation in Buenos Aires - Part 1"},{"categories":null,"contents":"Project Overview On this opportunity we\u0026rsquo;ll take from where we left off and extract time series data from specific coordinates. Remember on our last post we studied the severe drought of 2023 along Buenos Aires province, Argentina.\n","date":"July 30, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/chirps/chirps_2/","summary":"Project Overview On this opportunity we\u0026rsquo;ll take from where we left off and extract time series data from specific coordinates. Remember on our last post we studied the severe drought of 2023 along Buenos Aires province, Argentina.","tags":null,"title":"GEE Python API and CHIRPS: Analyzing precipitation in Buenos Aires - Part 2"},{"categories":null,"contents":"Project Overview Greetings! Welcome to the first part of a deep dive into Google Earth Engine (GEE) and its Python API. In this series, we\u0026rsquo;ll explore how to leverage the power of GEE for geospatial analysis, focusing on precipitation forecasting using the Global Forecast System (GFS) dataset.\nGFS is a widely-used weather forecast model developed by NOAA. It provides comprehensive weather data, including temperature, wind, and precipitation forecasts, on a global scale. The model delivers forecasts up to 16 days into the future, making it an invaluable tool for a wide range of applications.\nMoreover, we\u0026rsquo;ll explore the newly released XEE library. XEE combines the well-known xarray library with Google Earth Engine, providing powerful tools for handling and analyzing geospatial data. See more about XEE here.\nTo make this project reproducible, you can access all the code from my GitHub repository. Feel free to check it out, try the code yourself, and leave comments or suggestions.\nBy the end of this tutorial, you\u0026rsquo;ll be able to extract a series of precipitation data at 1-hour intervals and calculate cumulative values for a forecast window of 5 days for your coordinates of interest.\nAnalysis To begin with, we\u0026rsquo;ll import the necessary libraries and set our region of interest (ROI). Since I\u0026rsquo;m from Argentina, I\u0026rsquo;ve chosen region from the city I live in, Buenos Aires, as the focus for this analysis.\n# Libraries import ee import pandas as pd import numpy as np import xarray as xr from datetime import datetime, timedelta from tqdm import tqdm import matplotlib.pyplot as plt import matplotlib.dates as mdates ee.Initialize() #ee.Authenticate() isn\u0026#39;t necessary if you\u0026#39;ve your credentials stored. COORDs = [ [-60.09384640, -33.11803785], [-56.61465669, -33.11803785], [-56.61465669, -35.91630163], [-60.09384640, -35.91630163] ] ROI = ee.Geometry.Polygon(COORDs) Now we\u0026rsquo;ll define our dates of interest. I find it relevant to get the accumulated precipitation from the current date onward. For this, we\u0026rsquo;ll select the simulation that starts at T00, which is the initial run of the day. The GFS model performs four simulations daily at 00:00, 06:00, 12:00, and 18:00 UTC. We\u0026rsquo;ll focus on the T00 run to get the forecast data for our analysis. # Select the simulation launched at T00 to obtain the accumulated precipitation for the current day DATE_START = f\u0026#34;{datetime.strftime(datetime.now(), \u0026#39;%Y-%m-%d\u0026#39;)}T00:00\u0026#34; DATE_END = f\u0026#34;{datetime.strftime(datetime.now(), \u0026#39;%Y-%m-%d\u0026#39;)}T06:00\u0026#34; Now we\u0026rsquo;ll create an image collection using the region and dates of interest that we\u0026rsquo;ve defined previously. For more information on this dataset, you can consult the GEE catalog here. Additionally, we\u0026rsquo;ll select the precipitation band and extract the spatial resolution and projection of the data.\nTo facilitate data management and analysis, we\u0026rsquo;ll convert the image collection to an xarray dataset using the XEE library. This conversion allows us to leverage xarray\u0026rsquo;s powerful capabilities for handling multi-dimensional arrays, making it much easier to manipulate and analyze the dataset. C_01 = ee.ImageCollection(\u0026#34;NOAA/GFS0P25\u0026#34;).map(lambda image: image.clip(ROI))\\ .filterDate(DATE_START, DATE_END)\\ .filterMetadata(\u0026#34;forecast_hours\u0026#34;, \u0026#34;greater_than\u0026#34;, 0) # Select band of interest C_01 = C_01.select([\u0026#34;total_precipitation_surface\u0026#34;]) # Get the spatial resolution OS = C_01.first().projection().nominalScale().getInfo() # print(f\u0026#34;Original scale: {OS:.1f} m\u0026#34;) # Get projection data PROJ = C_01.first().select(0).projection() # Turn the image collection object into a xarray dataset DS_01 = xr.open_dataset(C_01, engine=\u0026#39;ee\u0026#39;, crs=\u0026#34;EPSG:4326\u0026#34;, projection=PROJ, geometry=ROI) Now we\u0026rsquo;ll structure our dataset. First, we\u0026rsquo;ll rename the precipitation band to something more descriptive. Next, we\u0026rsquo;ll slice the dataset to include only the first 120 records. This is because GFS data provides hourly frequency forecasts for the first 5 days. For longer-term forecasts, the data shifts to a 3-hour frequency, which we can exclude since we are\u0026rsquo;nt interested.\nAfter defining the initial parameters, we\u0026rsquo;ll create a pandas date range starting from DATE_START and spanning 120 hours with an hourly frequency.\nNext, we update the xarray dataset by assigning our date range FyH as the new temporal coordinate, replacing the original time dimension. We then drop the old time variable and introduce a new data array, FH (forecast hours), which indexes each forecast hour from 1 to 120. This reorganization makes the dataset more intuitive and easier to work with for further analysis and visualization.\n# Rename band DS_01 = DS_01.rename({\u0026#34;total_precipitation_surface\u0026#34; : \u0026#34;PPT\u0026#34;}) # Filter first 120 registers DS_01 = DS_01.isel(time=slice(0, 120)) # Create a pandas daterange starting from DATE_START and spanning 120 hours FyH = pd.date_range(start=DATE_START, freq=\u0026#34;1H\u0026#34;, periods=120+1)[1:] DS_01 = DS_01.assign_coords(FyH=(\u0026#34;time\u0026#34;, FyH)) DS_01 = DS_01.swap_dims({\u0026#34;time\u0026#34; : \u0026#34;FyH\u0026#34;}) DS_01 = DS_01.drop_vars(\u0026#34;time\u0026#34;) DS_01[\u0026#34;FH\u0026#34;] = xr.DataArray(np.arange(1, 121), dims=\u0026#34;FyH\u0026#34;) Now comes a tricky part. GFS data reports precipitation as cumulative values, resetting every 6 hours. To extract hourly precipitation values, we first create a new data array, H, using the modulo operator to identify these 6-hour periods. We then calculate hourly increments by finding the difference between consecutive precipitation values (PPT_D). To handle the 6-hour reset accurately, we use the where method as follows: PPT_D remains unchanged except where the previous H value was zero, in which case PPT_D is set equal to PPT. This ensures correct hourly precipitation data. Finally we compute the cumulative precipitation for the 5 day period. # Modula operator. Possible values are 0, 1, 2, 3, 4 and 5 DS_01[\u0026#34;H\u0026#34;] = DS_01[\u0026#34;FH\u0026#34;] % 6 # One hour increments DS_01[\u0026#34;PPT_D\u0026#34;] = DS_01[\u0026#34;PPT\u0026#34;].diff(dim=\u0026#34;FyH\u0026#34;) # PPT_D remains the same except where the previous H value was equal to 0 DS_01[\u0026#34;PPT_D\u0026#34;] = DS_01[\u0026#34;PPT_D\u0026#34;].where(DS_01[\u0026#34;H\u0026#34;].shift(FyH=1) != 0, DS_01[\u0026#34;PPT\u0026#34;]) # Calculate cumulative ppt along the FyH dimension DS_01[\u0026#34;CUMSUM\u0026#34;] = DS_01[\u0026#34;PPT_D\u0026#34;].cumsum(dim=\u0026#34;FyH\u0026#34;) Next, and nearing the end, we\u0026rsquo;ll convert the dataset into a Pandas dataframe. Specifically, we\u0026rsquo;ll extract precipitation data for specific coordinates of interest within the region we\u0026rsquo;ve defined previously. This will yield the precipitation data from the nearest pixel in the dataset to the provided coordinates. LON, LAT = -58.46633, -34.59960 DF_01 = DS_01.sel(lon=LON, lat=LAT, method=\u0026#34;nearest\u0026#34;).to_dataframe().drop(columns={\u0026#34;lon\u0026#34;, \u0026#34;lat\u0026#34;}) Visualization As a final step, we\u0026rsquo;ll create a plot to visualize our results using Matplotlib\u0026rsquo;s capabilities. Below is the final piece of code and the corresponding output from our analysis: fig, ax = plt.subplots(2, 1, figsize=(12, 6), gridspec_kw={\u0026#34;height_ratios\u0026#34; : [1, .6]}, sharex=True) ax[0].bar(DF_01.index, DF_01[\u0026#34;PPT_D\u0026#34;], label=\u0026#34;Hourly Ppt.\u0026#34;, color=\u0026#34;black\u0026#34;, zorder=5, width=.025) ax[0].set_title(f\u0026#34;Hourly precipitation forecast - GFS Model (SIM.: {DATE_START})\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) # Set y range and ticks ax[0].set_ylim(0, 15) ax[0].yaxis.set_ticks(np.arange(0, 15+1, 1)) ax[1].plot(DF_01.index, DF_01[\u0026#34;CUMSUM\u0026#34;], label=\u0026#34;Cumulative Ppt.\u0026#34;, color=\u0026#34;firebrick\u0026#34;, zorder=5) ax[1].set_title(f\u0026#34;Cumulative precipitation forecast - GFS Model (SIM.: {DATE_START})\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) # Set y range and ticks ax[1].set_ylim(0, 50) ax[1].yaxis.set_ticks(np.arange(0, 50+10, 10)) # Figure settings along both axis for i in [0, 1]: ax[i].set_ylabel(\u0026#34;[mm]\u0026#34;) ax[i].legend(loc=\u0026#34;upper left\u0026#34;) ax[i].grid(alpha=.5) ax[i].tick_params(labelbottom=True) ax[i].tick_params(axis=\u0026#34;both\u0026#34;, which=\u0026#34;major\u0026#34;) DATE_FMT = mdates.DateFormatter(\u0026#39;%d-%mT%H\u0026#39;) ax[i].xaxis.set_major_formatter(DATE_FMT) ax[i].xaxis.set_major_locator(mdates.HourLocator(byhour=[0, 6, 12, 18])) ax[i].tick_params(axis=\u0026#34;x\u0026#34;, labelrotation=-90) fig.tight_layout() plt.show(); Conclusion Looks like we might be expecting some heavy rain this weekend, so watch out! I hope this tutorial was useful for understanding how to extract and analyze precipitation data using the GFS dataset in Google Earth Engine and its Python API. In our next article, we\u0026rsquo;ll go one step further by creating spatial maps for a broader region, leveraging the full capabilities of the XEE library alongside new tools like Geopandas and Cartopy. Stay tuned!\n","date":"July 30, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/gfs/gfs_1/","summary":"Project Overview Greetings! Welcome to the first part of a deep dive into Google Earth Engine (GEE) and its Python API. In this series, we\u0026rsquo;ll explore how to leverage the power of GEE for geospatial analysis, focusing on precipitation forecasting using the Global Forecast System (GFS) dataset.\nGFS is a widely-used weather forecast model developed by NOAA. It provides comprehensive weather data, including temperature, wind, and precipitation forecasts, on a global scale.","tags":null,"title":"GEE Python API and Precipitation Forecasting - Part 1"},{"categories":null,"contents":"Project Overview Hello again! Welcome to the continuation of our deep dive into precipitation forecasting using the GFS dataset and the GEE Python API. In our previous post, we demonstrated how to use the GEE Python API along with the XEE library (an integration of GEE and xarray) to forecast precipitation for specific coordinates. This time, we’re going to expand our analysis to cover an entire region. Besides, we\u0026rsquo;ll leverage additional libraries such as Geopandas and Cartopy to create comprehensive spatial maps of precipitation forecasts.\nThe code builds upon what we covered earlier. You can find the Jupyter notebook in my GitHub repository here.\nBy the end of this tutorial, we\u0026rsquo;ll have a map of the cumulative precipitation over a region of interest (ROI) for a 5-day period. Additionally, we\u0026rsquo;ll provide the cumulative and discrete hourly precipitation at a specific location (point of interest or POI) within the ROI. This will enable us to not only get values at a specific location but also gain insight into the spatial pattern of the event.\nAnalysis and Visualization In our previous post, we ended up with two objects: DS_01 and DF_01. DS_01 is an xarray dataset containing the discrete and cumulative precipitation for our region of interest (ROI), while DF_01 is a pandas dataframe containing the same variables but specifically for our point of interest (POI).\nAs a result we created a plot of the variables contained within DF_01 that looked like this:\nNow we\u0026rsquo;ll begin by defining a new object named DS_02 that is an xarray object containing the cumulative precipitation for the 5 day period: # Create an image that\u0026#39;s the cumulated precipitation for the entire period. DS_02 = DS_01[\u0026#34;CUMSUM\u0026#34;].isel(FyH=-1) - DS_01[\u0026#34;CUMSUM\u0026#34;].isel(FyH=0) Next, we\u0026rsquo;ll define a geodataframe containing the longitude and latitude of our point of interest (POI): # Create a geodataframe with the coordinates of the point of interest # First we define a dataframe and then we turn it into a geodataframe DF_POI = pd.DataFrame({\u0026#39;LON\u0026#39;: [LON], \u0026#39;LAT\u0026#39;: [LAT]}) GDF_POI = gpd.GeoDataFrame(DF_POI, geometry=gpd.points_from_xy(DF_POI[\u0026#34;LON\u0026#34;], DF_POI[\u0026#34;LAT\u0026#34;]), crs=\u0026#34;EPSG:4326\u0026#34;).drop(columns=[\u0026#34;LON\u0026#34;, \u0026#34;LAT\u0026#34;]) Now, we can make our first map with the following code. Note that we are plotting an xarray object by leveraging the integration between xarray and matplotlib. We selected a discrete blues colorbar and set its range and step. Moreover, we took advantage of some of Cartopy\u0026rsquo;s capabilities, such as setting the map projection and adding coastlines for context. Finally, we\u0026rsquo;ve used Geopandas to plot the location of the point of interest (POI) on the map.\nfig, ax = plt.subplots(1, 1, figsize=(5, 5), subplot_kw={\u0026#39;projection\u0026#39;: ccrs.PlateCarree()}, constrained_layout=True) im =DS_02.plot(x=\u0026#34;lon\u0026#34;, y=\u0026#34;lat\u0026#34;, ax=ax, vmin=0, vmax=50, cmap=\u0026#34;Blues\u0026#34;, add_colorbar=False, levels=11) # POI ax.plot(GDF_POI.geometry.x, GDF_POI.geometry.y, \u0026#39;o\u0026#39;, color=\u0026#34;saddlebrown\u0026#34;, markersize=5, markeredgecolor=\u0026#34;black\u0026#34;, label=\u0026#34;POI\u0026#34;) # Add a title to the whole figure ax.set_title(f\u0026#34;Cumulative precipitation forecast\\n{pd.to_datetime(DATE_START):%Y-%m-%d} to {(pd.to_datetime(DATE_START) + timedelta(days=5)):%Y-%m-%d} (UTC-0)\u0026#34;, fontweight=\u0026#39;bold\u0026#39;) # Add land boundaries ax.add_feature(cf.COASTLINE, linewidth=1.5, edgecolor=\u0026#39;black\u0026#39;) # Grid settings GLs = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, x_inline=False, y_inline=False, linewidth=.5, color=\u0026#39;gray\u0026#39;, alpha=0.2, linestyle=\u0026#39;--\u0026#39;) GLs.top_labels = False GLs.right_labels = False # Set x and y ticks at 1-degree intervals using MultipleLocator GLs.xlocator = MultipleLocator(0.5) GLs.ylocator = MultipleLocator(0.5) # Create colorbar with specified ticks cbar = fig.colorbar(im, ax=ax, shrink=0.75) cbar.set_ticks(range(0, 50+5, 5)) cbar.set_label(\u0026#34;[mm]\u0026#34;, rotation=-90, labelpad=10) # Legend ax.legend(loc=\u0026#34;upper right\u0026#34;) # Add a footnote to the bottom left corner fig.text(0.02, 0.10, f\u0026#34;GFS Model (SIM.: {DATE_START})\u0026#34;, color=\u0026#39;gray\u0026#39;) plt.show(); Finally, we\u0026rsquo;ll bring everything together and visualize the map alongside the cumulative and discrete precipitation at the POI. We\u0026rsquo;ll use Matplotlib\u0026rsquo;s GridSpec method to create a well-organized layout. The code is extensive but achieves the desired result effectively.\nHere’s the complete code: # Create the main plot using gridspec fig = plt.figure(figsize=(12, 4.5), constrained_layout=True) GS = fig.add_gridspec(nrows=2, ncols=2, width_ratios=[.5, .75]) # Add a title to the whole figure fig.suptitle(f\u0026#34;Cumulative and hourly precipitation forecast {pd.to_datetime(DATE_START):%Y-%m-%d} to {(pd.to_datetime(DATE_START) + timedelta(days=5)):%Y-%m-%d} (UTC-0)\u0026#34;, fontweight=\u0026#39;bold\u0026#39;) # MAP ax_0 = fig.add_subplot(GS[:, 0], projection=ccrs.PlateCarree()) # ROI im =DS_02.plot(x=\u0026#34;lon\u0026#34;, y=\u0026#34;lat\u0026#34;, ax=ax_0, vmin=0, vmax=50, cmap=\u0026#34;Blues\u0026#34;, add_colorbar=False, levels=11) # POI ax_0.plot(GDF_POI.geometry.x, GDF_POI.geometry.y, \u0026#39;o\u0026#39;, color=\u0026#34;saddlebrown\u0026#34;, markersize=5, markeredgecolor=\u0026#34;black\u0026#34;, label=\u0026#34;POI\u0026#34;) ax_0.set_title(f\u0026#34;Cumulative precipitation over ROI\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) # Add land boundaries ax_0.add_feature(cf.COASTLINE, linewidth=1.5, edgecolor=\u0026#39;black\u0026#39;) # Grid settings GLs = ax_0.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, x_inline=False, y_inline=False, linewidth=.5, color=\u0026#39;gray\u0026#39;, alpha=0.2, linestyle=\u0026#39;--\u0026#39;) # Visibility GLs.top_labels = False GLs.right_labels = False # Set x and y ticks at 1-degree intervals using MultipleLocator GLs.xlocator = MultipleLocator(0.5) GLs.ylocator = MultipleLocator(0.5) # Create colorbar with specified ticks cbar = fig.colorbar(im, ax=ax_0, shrink=0.75) cbar.set_ticks(range(0, 50+5, 5)) cbar.set_label(\u0026#34;[mm]\u0026#34;, rotation=-90, labelpad=10) # Legend ax_0.legend(loc=\u0026#34;upper right\u0026#34;) # Discrete Ppt ax_1 = fig.add_subplot(GS[0, 1]) ax_1.bar(DF_01.index, DF_01[\u0026#34;PPT_D\u0026#34;], label=\u0026#34;Hourly Ppt.\u0026#34;, color=\u0026#34;black\u0026#34;, zorder=5, width=.025) ax_1.set_title(f\u0026#34;Hourly precipitation over POI\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) # Set y range and ticks ax_1.set_ylim(0, 15) ax_1.yaxis.set_ticks(np.arange(0, 15+5, 5)) # Set x ticks to false ax_1.tick_params(labelbottom=False) # Cumulative Ppt ax_2 = fig.add_subplot(GS[1, 1]) ax_2.plot(DF_01.index, DF_01[\u0026#34;CUMSUM\u0026#34;], label=\u0026#34;Cumulative Ppt.\u0026#34;, color=\u0026#34;firebrick\u0026#34;, zorder=5) ax_2.set_title(f\u0026#34;Cumulative precipitation over POI\u0026#34;, fontweight=\u0026#34;bold\u0026#34;) # Set y range and ticks ax_2.set_ylim(0, 50) ax_2.yaxis.set_ticks(np.arange(0, 50+10, 10)) ax_2.tick_params(labelbottom=True) DATE_FMT = mdates.DateFormatter(\u0026#39;%d-%mT%H\u0026#39;) ax_2.xaxis.set_major_formatter(DATE_FMT) ax_2.xaxis.set_major_locator(mdates.HourLocator(byhour=[0, 6, 12, 18])) ax_2.tick_params(axis=\u0026#34;x\u0026#34;, labelrotation=-90) # Common properties for ax in [ax_1, ax_2]: ax.set_ylabel(\u0026#34;[mm]\u0026#34;) ax.legend(loc=\u0026#34;upper left\u0026#34;) ax.grid(alpha=.5) ax.tick_params(axis=\u0026#34;both\u0026#34;, which=\u0026#34;major\u0026#34;) ax.xaxis.set_major_locator(mdates.HourLocator(byhour=[0, 6, 12, 18])) # Add a footnote to the bottom left corner fig.text(0.02, 0.02, f\u0026#34;GFS Model (SIM.: {DATE_START})\u0026#34;, color=\u0026#39;gray\u0026#39;) plt.show(); Conclusion In this post, we\u0026rsquo;ve expanded our initial analysis from specific coordinates to a broader region, allowing us to visualize both the spatial distribution and temporal evolution of precipitation. By leveraging the capabilities of GEE, XEE, and additional libraries such as Geopandas and Cartopy, we\u0026rsquo;ve created a comprehensive map and time series plots that provide a detailed understanding of precipitation forecasts.\n","date":"July 30, 2024","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/posts/gfs/gfs_2/","summary":"Project Overview Hello again! Welcome to the continuation of our deep dive into precipitation forecasting using the GFS dataset and the GEE Python API. In our previous post, we demonstrated how to use the GEE Python API along with the XEE library (an integration of GEE and xarray) to forecast precipitation for specific coordinates. This time, we’re going to expand our analysis to cover an entire region. Besides, we\u0026rsquo;ll leverage additional libraries such as Geopandas and Cartopy to create comprehensive spatial maps of precipitation forecasts.","tags":null,"title":"GEE Python API and Precipitation Forecasting - Part 2"},{"categories":null,"contents":"Go Notes ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/go/_index.bn/","summary":"Go Notes ","tags":null,"title":"Go এর নোট সমূহ"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/_index.bn/","summary":"","tags":null,"title":"নোট সমূহ"},{"categories":null,"contents":"Bash Notes ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/notes/bash/_index.bn/","summary":"Bash Notes ","tags":null,"title":"ব্যাশের নোট সমূহ"}]